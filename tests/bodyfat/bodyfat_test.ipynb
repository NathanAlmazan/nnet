{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Density</th>\n",
       "      <th>BodyFat</th>\n",
       "      <th>Age</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height</th>\n",
       "      <th>Neck</th>\n",
       "      <th>Chest</th>\n",
       "      <th>Abdomen</th>\n",
       "      <th>Hip</th>\n",
       "      <th>Thigh</th>\n",
       "      <th>Knee</th>\n",
       "      <th>Ankle</th>\n",
       "      <th>Biceps</th>\n",
       "      <th>Forearm</th>\n",
       "      <th>Wrist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0708</td>\n",
       "      <td>12.3</td>\n",
       "      <td>23</td>\n",
       "      <td>154.25</td>\n",
       "      <td>67.75</td>\n",
       "      <td>36.2</td>\n",
       "      <td>93.1</td>\n",
       "      <td>85.2</td>\n",
       "      <td>94.5</td>\n",
       "      <td>59.0</td>\n",
       "      <td>37.3</td>\n",
       "      <td>21.9</td>\n",
       "      <td>32.0</td>\n",
       "      <td>27.4</td>\n",
       "      <td>17.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0853</td>\n",
       "      <td>6.1</td>\n",
       "      <td>22</td>\n",
       "      <td>173.25</td>\n",
       "      <td>72.25</td>\n",
       "      <td>38.5</td>\n",
       "      <td>93.6</td>\n",
       "      <td>83.0</td>\n",
       "      <td>98.7</td>\n",
       "      <td>58.7</td>\n",
       "      <td>37.3</td>\n",
       "      <td>23.4</td>\n",
       "      <td>30.5</td>\n",
       "      <td>28.9</td>\n",
       "      <td>18.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0414</td>\n",
       "      <td>25.3</td>\n",
       "      <td>22</td>\n",
       "      <td>154.00</td>\n",
       "      <td>66.25</td>\n",
       "      <td>34.0</td>\n",
       "      <td>95.8</td>\n",
       "      <td>87.9</td>\n",
       "      <td>99.2</td>\n",
       "      <td>59.6</td>\n",
       "      <td>38.9</td>\n",
       "      <td>24.0</td>\n",
       "      <td>28.8</td>\n",
       "      <td>25.2</td>\n",
       "      <td>16.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0751</td>\n",
       "      <td>10.4</td>\n",
       "      <td>26</td>\n",
       "      <td>184.75</td>\n",
       "      <td>72.25</td>\n",
       "      <td>37.4</td>\n",
       "      <td>101.8</td>\n",
       "      <td>86.4</td>\n",
       "      <td>101.2</td>\n",
       "      <td>60.1</td>\n",
       "      <td>37.3</td>\n",
       "      <td>22.8</td>\n",
       "      <td>32.4</td>\n",
       "      <td>29.4</td>\n",
       "      <td>18.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0340</td>\n",
       "      <td>28.7</td>\n",
       "      <td>24</td>\n",
       "      <td>184.25</td>\n",
       "      <td>71.25</td>\n",
       "      <td>34.4</td>\n",
       "      <td>97.3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>101.9</td>\n",
       "      <td>63.2</td>\n",
       "      <td>42.2</td>\n",
       "      <td>24.0</td>\n",
       "      <td>32.2</td>\n",
       "      <td>27.7</td>\n",
       "      <td>17.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Density  BodyFat  Age  Weight  Height  Neck  Chest  Abdomen    Hip  Thigh  \\\n",
       "0   1.0708     12.3   23  154.25   67.75  36.2   93.1     85.2   94.5   59.0   \n",
       "1   1.0853      6.1   22  173.25   72.25  38.5   93.6     83.0   98.7   58.7   \n",
       "2   1.0414     25.3   22  154.00   66.25  34.0   95.8     87.9   99.2   59.6   \n",
       "3   1.0751     10.4   26  184.75   72.25  37.4  101.8     86.4  101.2   60.1   \n",
       "4   1.0340     28.7   24  184.25   71.25  34.4   97.3    100.0  101.9   63.2   \n",
       "\n",
       "   Knee  Ankle  Biceps  Forearm  Wrist  \n",
       "0  37.3   21.9    32.0     27.4   17.1  \n",
       "1  37.3   23.4    30.5     28.9   18.2  \n",
       "2  38.9   24.0    28.8     25.2   16.6  \n",
       "3  37.3   22.8    32.4     29.4   18.2  \n",
       "4  42.2   24.0    32.2     27.7   17.7  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "# define dataset\n",
    "df = pd.read_csv('bodyfat_dataset.csv')\n",
    "df.sample(frac = 1) # shuffle\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(252, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = df.loc[:, ['Density', 'BodyFat']]\n",
    "labels = np.array(labels)\n",
    "\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height</th>\n",
       "      <th>Neck</th>\n",
       "      <th>Chest</th>\n",
       "      <th>Abdomen</th>\n",
       "      <th>Hip</th>\n",
       "      <th>Thigh</th>\n",
       "      <th>Knee</th>\n",
       "      <th>Ankle</th>\n",
       "      <th>Biceps</th>\n",
       "      <th>Forearm</th>\n",
       "      <th>Wrist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>154.25</td>\n",
       "      <td>67.75</td>\n",
       "      <td>36.2</td>\n",
       "      <td>93.1</td>\n",
       "      <td>85.2</td>\n",
       "      <td>94.5</td>\n",
       "      <td>59.0</td>\n",
       "      <td>37.3</td>\n",
       "      <td>21.9</td>\n",
       "      <td>32.0</td>\n",
       "      <td>27.4</td>\n",
       "      <td>17.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>173.25</td>\n",
       "      <td>72.25</td>\n",
       "      <td>38.5</td>\n",
       "      <td>93.6</td>\n",
       "      <td>83.0</td>\n",
       "      <td>98.7</td>\n",
       "      <td>58.7</td>\n",
       "      <td>37.3</td>\n",
       "      <td>23.4</td>\n",
       "      <td>30.5</td>\n",
       "      <td>28.9</td>\n",
       "      <td>18.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>154.00</td>\n",
       "      <td>66.25</td>\n",
       "      <td>34.0</td>\n",
       "      <td>95.8</td>\n",
       "      <td>87.9</td>\n",
       "      <td>99.2</td>\n",
       "      <td>59.6</td>\n",
       "      <td>38.9</td>\n",
       "      <td>24.0</td>\n",
       "      <td>28.8</td>\n",
       "      <td>25.2</td>\n",
       "      <td>16.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26</td>\n",
       "      <td>184.75</td>\n",
       "      <td>72.25</td>\n",
       "      <td>37.4</td>\n",
       "      <td>101.8</td>\n",
       "      <td>86.4</td>\n",
       "      <td>101.2</td>\n",
       "      <td>60.1</td>\n",
       "      <td>37.3</td>\n",
       "      <td>22.8</td>\n",
       "      <td>32.4</td>\n",
       "      <td>29.4</td>\n",
       "      <td>18.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>184.25</td>\n",
       "      <td>71.25</td>\n",
       "      <td>34.4</td>\n",
       "      <td>97.3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>101.9</td>\n",
       "      <td>63.2</td>\n",
       "      <td>42.2</td>\n",
       "      <td>24.0</td>\n",
       "      <td>32.2</td>\n",
       "      <td>27.7</td>\n",
       "      <td>17.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Weight  Height  Neck  Chest  Abdomen    Hip  Thigh  Knee  Ankle  \\\n",
       "0   23  154.25   67.75  36.2   93.1     85.2   94.5   59.0  37.3   21.9   \n",
       "1   22  173.25   72.25  38.5   93.6     83.0   98.7   58.7  37.3   23.4   \n",
       "2   22  154.00   66.25  34.0   95.8     87.9   99.2   59.6  38.9   24.0   \n",
       "3   26  184.75   72.25  37.4  101.8     86.4  101.2   60.1  37.3   22.8   \n",
       "4   24  184.25   71.25  34.4   97.3    100.0  101.9   63.2  42.2   24.0   \n",
       "\n",
       "   Biceps  Forearm  Wrist  \n",
       "0    32.0     27.4   17.1  \n",
       "1    30.5     28.9   18.2  \n",
       "2    28.8     25.2   16.6  \n",
       "3    32.4     29.4   18.2  \n",
       "4    32.2     27.7   17.7  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop the data labels\n",
    "df = df.drop('Density', axis=1)\n",
    "df = df.drop('BodyFat', axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(252, 13)\n",
      "(252, 2)\n"
     ]
    }
   ],
   "source": [
    "# scale data\n",
    "data = np.array(df)\n",
    "\n",
    "x_scaler = MinMaxScaler()\n",
    "y_scaler = MinMaxScaler()\n",
    "\n",
    "X = x_scaler.fit_transform(data)\n",
    "Y = y_scaler.fit_transform(labels)\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 13)\n",
      "(200, 2)\n",
      "(52, 13)\n",
      "(52, 2)\n"
     ]
    }
   ],
   "source": [
    "X_train = X[:200]\n",
    "Y_train = Y[:200]\n",
    "\n",
    "X_test = X[-52:]\n",
    "Y_test = Y[-52:]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Loss: 0.12379817426685623 Validation Loss: 0.14050318101811088 \n",
      "Epoch: 2 Loss: 0.05812748279264974 Validation Loss: 0.07564440975213932 \n",
      "Epoch: 3 Loss: 0.04703234365176614 Validation Loss: 0.051750534659612685 \n",
      "Epoch: 4 Loss: 0.04343606508632689 Validation Loss: 0.06760017141525196 \n",
      "Epoch: 5 Loss: 0.037405316972636195 Validation Loss: 0.04596108964614333 \n",
      "Epoch: 6 Loss: 0.033634991409882666 Validation Loss: 0.050837606530146066 \n",
      "Epoch: 7 Loss: 0.030651093428679922 Validation Loss: 0.04174659156052127 \n",
      "Epoch: 8 Loss: 0.02841130376015488 Validation Loss: 0.04164028927328049 \n",
      "Epoch: 9 Loss: 0.026479874283395603 Validation Loss: 0.03715432328511255 \n",
      "Epoch: 10 Loss: 0.024900494138333843 Validation Loss: 0.03572751838205565 \n",
      "Epoch: 11 Loss: 0.023527024426976278 Validation Loss: 0.03288349669828933 \n",
      "Epoch: 12 Loss: 0.022422599794466716 Validation Loss: 0.031407369004363035 \n",
      "Epoch: 13 Loss: 0.021488622974624436 Validation Loss: 0.029552653766768928 \n",
      "Epoch: 14 Loss: 0.020856879850168982 Validation Loss: 0.028293387450170772 \n",
      "Epoch: 15 Loss: 0.020684267446982797 Validation Loss: 0.028023254852551773 \n",
      "Epoch: 16 Loss: 0.021398129511634494 Validation Loss: 0.027105047110269724 \n",
      "Epoch: 17 Loss: 0.022479615839447707 Validation Loss: 0.029838993611564852 \n",
      "Epoch: 18 Loss: 0.02220636378108984 Validation Loss: 0.027046287829254702 \n",
      "Epoch: 19 Loss: 0.020305180684845738 Validation Loss: 0.027452075644035512 \n",
      "Epoch: 20 Loss: 0.01934474326177411 Validation Loss: 0.024184090018287377 \n",
      "Epoch: 21 Loss: 0.018511254993154494 Validation Loss: 0.025133882702292974 \n",
      "Epoch: 22 Loss: 0.018071120117816995 Validation Loss: 0.022658678453826766 \n",
      "Epoch: 23 Loss: 0.017701029758288623 Validation Loss: 0.023984849436046618 \n",
      "Epoch: 24 Loss: 0.017502507102768204 Validation Loss: 0.021641167469369223 \n",
      "Epoch: 25 Loss: 0.017362051551003187 Validation Loss: 0.023622884729324636 \n",
      "Epoch: 26 Loss: 0.017415452787421775 Validation Loss: 0.020887013892577428 \n",
      "Epoch: 27 Loss: 0.01752106066160135 Validation Loss: 0.024092300074158263 \n",
      "Epoch: 28 Loss: 0.01782254651048887 Validation Loss: 0.020516136415006374 \n",
      "Epoch: 29 Loss: 0.017813639083260266 Validation Loss: 0.024729741481587745 \n",
      "Epoch: 30 Loss: 0.017813623234395982 Validation Loss: 0.020188516740436997 \n",
      "Epoch: 31 Loss: 0.017279340072600916 Validation Loss: 0.024137978419609133 \n",
      "Epoch: 32 Loss: 0.0169710412431566 Validation Loss: 0.019582443424419275 \n",
      "Epoch: 33 Loss: 0.016478443232320828 Validation Loss: 0.023080806835594877 \n",
      "Epoch: 34 Loss: 0.016250384629617563 Validation Loss: 0.019091205133118183 \n",
      "Epoch: 35 Loss: 0.01597484746977644 Validation Loss: 0.022446162096532753 \n",
      "Epoch: 36 Loss: 0.015888627420775802 Validation Loss: 0.01873234167995575 \n",
      "Epoch: 37 Loss: 0.01577075972255073 Validation Loss: 0.02233047058235502 \n",
      "Epoch: 38 Loss: 0.015816270716976288 Validation Loss: 0.018457221793300345 \n",
      "Epoch: 39 Loss: 0.015795571601213084 Validation Loss: 0.022624554013058885 \n",
      "Epoch: 40 Loss: 0.01592160287932055 Validation Loss: 0.018283116861185736 \n",
      "Epoch: 41 Loss: 0.01586575057898565 Validation Loss: 0.022984679011931557 \n",
      "Epoch: 42 Loss: 0.01592145340253107 Validation Loss: 0.0181610135983564 \n",
      "Epoch: 43 Loss: 0.015704252701552377 Validation Loss: 0.022946995975551523 \n",
      "Epoch: 44 Loss: 0.015627985916045056 Validation Loss: 0.01799539262789203 \n",
      "Epoch: 45 Loss: 0.015345373605811759 Validation Loss: 0.02256126146829341 \n",
      "Epoch: 46 Loss: 0.01524543634062323 Validation Loss: 0.017808751348936027 \n",
      "Epoch: 47 Loss: 0.015025622048780432 Validation Loss: 0.02222161558101678 \n",
      "Epoch: 48 Loss: 0.014982656780644192 Validation Loss: 0.017638884510173036 \n",
      "Epoch: 49 Loss: 0.014849522193036337 Validation Loss: 0.022132393105711596 \n",
      "Epoch: 50 Loss: 0.014877910682270123 Validation Loss: 0.01749429797631316 \n",
      "Epoch: 51 Loss: 0.014799658736578665 Validation Loss: 0.022272791922607487 \n",
      "Epoch: 52 Loss: 0.0148695010583087 Validation Loss: 0.01738203245773168 \n",
      "Epoch: 53 Loss: 0.01478120864487784 Validation Loss: 0.022465400975097947 \n",
      "Epoch: 54 Loss: 0.014828819416115736 Validation Loss: 0.017286407765040326 \n",
      "Epoch: 55 Loss: 0.014675931989066643 Validation Loss: 0.022496093532473692 \n",
      "Epoch: 56 Loss: 0.014666525077061308 Validation Loss: 0.017175059958612814 \n",
      "Epoch: 57 Loss: 0.014470353750478216 Validation Loss: 0.02233784473606735 \n",
      "Epoch: 58 Loss: 0.014436153874446984 Validation Loss: 0.017047019452747756 \n",
      "Epoch: 59 Loss: 0.014254798143077991 Validation Loss: 0.022149289499957484 \n",
      "Epoch: 60 Loss: 0.014240191633118453 Validation Loss: 0.016919978265899912 \n",
      "Epoch: 61 Loss: 0.014100022374286314 Validation Loss: 0.022064757834711256 \n",
      "Epoch: 62 Loss: 0.014120635251296955 Validation Loss: 0.016803595912729855 \n",
      "Epoch: 63 Loss: 0.014009938037169744 Validation Loss: 0.02209657921041854 \n",
      "Epoch: 64 Loss: 0.014051979132483105 Validation Loss: 0.016700240098163947 \n",
      "Epoch: 65 Loss: 0.013938698536021386 Validation Loss: 0.02215873305861706 \n",
      "Epoch: 66 Loss: 0.013973502945537564 Validation Loss: 0.016603791830155038 \n",
      "Epoch: 67 Loss: 0.01383291604937661 Validation Loss: 0.022150046095882427 \n",
      "Epoch: 68 Loss: 0.013845056985246868 Validation Loss: 0.016503817980679254 \n",
      "Epoch: 69 Loss: 0.013683449267252689 Validation Loss: 0.02205104395912313 \n",
      "Epoch: 70 Loss: 0.013684616066329109 Validation Loss: 0.016397970826922837 \n",
      "Epoch: 71 Loss: 0.013526316534832163 Validation Loss: 0.021927341029187412 \n",
      "Epoch: 72 Loss: 0.013536842622190402 Validation Loss: 0.016291194320205316 \n",
      "Epoch: 73 Loss: 0.013395848192761284 Validation Loss: 0.021845229299620825 \n",
      "Epoch: 74 Loss: 0.013424508196925707 Validation Loss: 0.016187950141970362 \n",
      "Epoch: 75 Loss: 0.01329575507897333 Validation Loss: 0.021813366846995433 \n",
      "Epoch: 76 Loss: 0.013336223645233802 Validation Loss: 0.016089418844773766 \n",
      "Epoch: 77 Loss: 0.013204385932572655 Validation Loss: 0.021789877647840333 \n",
      "Epoch: 78 Loss: 0.013243998895136309 Validation Loss: 0.01599288009059491 \n",
      "Epoch: 79 Loss: 0.013098748291866535 Validation Loss: 0.021729815306381097 \n",
      "Epoch: 80 Loss: 0.01313158818771143 Validation Loss: 0.015894283354231542 \n",
      "Epoch: 81 Loss: 0.01297639094487899 Validation Loss: 0.021628234961313744 \n",
      "Epoch: 82 Loss: 0.013007775215304803 Validation Loss: 0.015792640714292188 \n",
      "Epoch: 83 Loss: 0.012853169626665667 Validation Loss: 0.021515982253213613 \n",
      "Epoch: 84 Loss: 0.012891847688243266 Validation Loss: 0.015690305767334604 \n",
      "Epoch: 85 Loss: 0.01274350320459614 Validation Loss: 0.021421155542645506 \n",
      "Epoch: 86 Loss: 0.012792901772183965 Validation Loss: 0.015590039062878536 \n",
      "Epoch: 87 Loss: 0.01264792066761528 Validation Loss: 0.02134456803300673 \n",
      "Epoch: 88 Loss: 0.012704585213663841 Validation Loss: 0.015492387467506667 \n",
      "Epoch: 89 Loss: 0.012556521294403971 Validation Loss: 0.021267284161640136 \n",
      "Epoch: 90 Loss: 0.012614705205783125 Validation Loss: 0.01539521833155853 \n",
      "Epoch: 91 Loss: 0.012460656081362272 Validation Loss: 0.021173638120577078 \n",
      "Epoch: 92 Loss: 0.012517673082027524 Validation Loss: 0.015296306160878848 \n",
      "Epoch: 93 Loss: 0.012360556535565625 Validation Loss: 0.021064933536256523 \n",
      "Epoch: 94 Loss: 0.012417730925636137 Validation Loss: 0.015195869933291594 \n",
      "Epoch: 95 Loss: 0.012262500804072627 Validation Loss: 0.0209535577811258 \n",
      "Epoch: 96 Loss: 0.012321978501588848 Validation Loss: 0.015095825518099244 \n",
      "Epoch: 97 Loss: 0.012171092315888315 Validation Loss: 0.020848590348693147 \n",
      "Epoch: 98 Loss: 0.012232909227942767 Validation Loss: 0.01499763889171542 \n",
      "Epoch: 99 Loss: 0.012085489201702344 Validation Loss: 0.020748676737698087 \n",
      "Epoch: 100 Loss: 0.012147602985350415 Validation Loss: 0.01490135345063481 \n",
      "Epoch: 101 Loss: 0.012001796172538328 Validation Loss: 0.02064657063329771 \n",
      "Epoch: 102 Loss: 0.012062267628101643 Validation Loss: 0.014805991772450169 \n",
      "Epoch: 103 Loss: 0.011917694400129847 Validation Loss: 0.020537994018908448 \n",
      "Epoch: 104 Loss: 0.011976440850924188 Validation Loss: 0.014710653101089181 \n",
      "Epoch: 105 Loss: 0.01183439118679086 Validation Loss: 0.020425299268432805 \n",
      "Epoch: 106 Loss: 0.011892867536769188 Validation Loss: 0.014615311021969139 \n",
      "Epoch: 107 Loss: 0.011754603790522756 Validation Loss: 0.020313732887535994 \n",
      "Epoch: 108 Loss: 0.01181415363467027 Validation Loss: 0.014520704067763691 \n",
      "Epoch: 109 Loss: 0.011679441021383736 Validation Loss: 0.020205752480295127 \n",
      "Epoch: 110 Loss: 0.011740157441072875 Validation Loss: 0.014427628943217778 \n",
      "Epoch: 111 Loss: 0.011607420381088009 Validation Loss: 0.020099255234982467 \n",
      "Epoch: 112 Loss: 0.011668432033384713 Validation Loss: 0.014336371387222158 \n",
      "Epoch: 113 Loss: 0.011536122210364099 Validation Loss: 0.019990549741468702 \n",
      "Epoch: 114 Loss: 0.011596722898604896 Validation Loss: 0.014246793744731607 \n",
      "Epoch: 115 Loss: 0.011464434569312964 Validation Loss: 0.01987832947116754 \n",
      "Epoch: 116 Loss: 0.011524794658342712 Validation Loss: 0.014158859256468984 \n",
      "Epoch: 117 Loss: 0.011393145994996048 Validation Loss: 0.019764610919562855 \n",
      "Epoch: 118 Loss: 0.011453998151812477 Validation Loss: 0.014072904363494895 \n",
      "Epoch: 119 Loss: 0.01132368023072994 Validation Loss: 0.019652343767471145 \n",
      "Epoch: 120 Loss: 0.011385534370774022 Validation Loss: 0.013989408097612855 \n",
      "Epoch: 121 Loss: 0.011256628138790694 Validation Loss: 0.019542766085638784 \n",
      "Epoch: 122 Loss: 0.01131939687114512 Validation Loss: 0.013908627768179489 \n",
      "Epoch: 123 Loss: 0.011191494643153952 Validation Loss: 0.01943506380026169 \n",
      "Epoch: 124 Loss: 0.011254772224279428 Validation Loss: 0.013830508627604545 \n",
      "Epoch: 125 Loss: 0.01112753556753133 Validation Loss: 0.019328006090261012 \n",
      "Epoch: 126 Loss: 0.011191082683663976 Validation Loss: 0.013754895976788754 \n",
      "Epoch: 127 Loss: 0.011064574060464225 Validation Loss: 0.01922145553394987 \n",
      "Epoch: 128 Loss: 0.011128487883422864 Validation Loss: 0.013681773719943578 \n",
      "Epoch: 129 Loss: 0.011003020673954781 Validation Loss: 0.019116359747704245 \n",
      "Epoch: 130 Loss: 0.011067518328416251 Validation Loss: 0.01361129395535564 \n",
      "Epoch: 131 Loss: 0.010943306626019403 Validation Loss: 0.0190136783082117 \n",
      "Epoch: 132 Loss: 0.011008446901447826 Validation Loss: 0.013543627905010156 \n",
      "Epoch: 133 Loss: 0.01088544912557536 Validation Loss: 0.01891359406554514 \n",
      "Epoch: 134 Loss: 0.010951083191708375 Validation Loss: 0.013478832521880398 \n",
      "Epoch: 135 Loss: 0.010829133769518938 Validation Loss: 0.018815693378087653 \n",
      "Epoch: 136 Loss: 0.010895067991822232 Validation Loss: 0.013416856087405253 \n",
      "Epoch: 137 Loss: 0.010774089187381621 Validation Loss: 0.018719666208991827 \n",
      "Epoch: 138 Loss: 0.01084024073321772 Validation Loss: 0.013357640648773171 \n",
      "Epoch: 139 Loss: 0.010720307993497746 Validation Loss: 0.018625696392063983 \n",
      "Epoch: 140 Loss: 0.010786703992255797 Validation Loss: 0.013301202747101866 \n",
      "Epoch: 141 Loss: 0.010667939536457283 Validation Loss: 0.018534241156354145 \n",
      "Epoch: 142 Loss: 0.010734610224846595 Validation Loss: 0.013247629368443061 \n",
      "Epoch: 143 Loss: 0.010617049310929723 Validation Loss: 0.018445584381196586 \n",
      "Epoch: 144 Loss: 0.010683958647510216 Validation Loss: 0.013197015858128726 \n",
      "Epoch: 145 Loss: 0.01056752085011003 Validation Loss: 0.018359680489491145 \n",
      "Epoch: 146 Loss: 0.010634595952760763 Validation Loss: 0.013149405632719295 \n",
      "Epoch: 147 Loss: 0.01051916363866084 Validation Loss: 0.018276383975557656 \n",
      "Epoch: 148 Loss: 0.01058636091763097 Validation Loss: 0.013104788628564897 \n",
      "Epoch: 149 Loss: 0.010471860922286531 Validation Loss: 0.018195703669900833 \n",
      "Epoch: 150 Loss: 0.010539199616513279 Validation Loss: 0.013063221971172533 \n",
      "Epoch: 151 Loss: 0.010425570083053271 Validation Loss: 0.018117701844592497 \n",
      "Epoch: 152 Loss: 0.010493170384458699 Validation Loss: 0.013025050038046963 \n",
      "Epoch: 153 Loss: 0.010380186252720773 Validation Loss: 0.018042209966078908 \n",
      "Epoch: 154 Loss: 0.010448356122160694 Validation Loss: 0.012990767852622773 \n",
      "Epoch: 155 Loss: 0.010335559058062245 Validation Loss: 0.01796937147320074 \n",
      "Epoch: 156 Loss: 0.010404625625116754 Validation Loss: 0.012959546542915583 \n",
      "Epoch: 157 Loss: 0.010292013168114704 Validation Loss: 0.01790163489127492 \n",
      "Epoch: 158 Loss: 0.010361281494563153 Validation Loss: 0.012927720553290223 \n",
      "Epoch: 159 Loss: 0.010250565423124147 Validation Loss: 0.01784060355521076 \n",
      "Epoch: 160 Loss: 0.010318477996122375 Validation Loss: 0.012902273387770903 \n",
      "Epoch: 161 Loss: 0.010207655511808465 Validation Loss: 0.017758023025097634 \n",
      "Epoch: 162 Loss: 0.010285286121704824 Validation Loss: 0.012923759633822985 \n",
      "Epoch: 163 Loss: 0.010152290980040677 Validation Loss: 0.017672990486200243 \n",
      "Epoch: 164 Loss: 0.010241168303536769 Validation Loss: 0.012850139948051833 \n",
      "Epoch: 165 Loss: 0.010140034533714558 Validation Loss: 0.017715552942867342 \n",
      "Epoch: 166 Loss: 0.010190322648665186 Validation Loss: 0.012780942011335202 \n",
      "Epoch: 167 Loss: 0.01010788529053961 Validation Loss: 0.017636699823508496 \n",
      "Epoch: 168 Loss: 0.010165803427135444 Validation Loss: 0.01281327984300785 \n",
      "Epoch: 169 Loss: 0.01006104161194346 Validation Loss: 0.017528523357864517 \n",
      "Epoch: 170 Loss: 0.010153930898834039 Validation Loss: 0.012876049048780185 \n",
      "Epoch: 171 Loss: 0.010005500427539062 Validation Loss: 0.017471569727352594 \n",
      "Epoch: 172 Loss: 0.010087618847296096 Validation Loss: 0.01277628633826954 \n",
      "Epoch: 173 Loss: 0.009982637508740616 Validation Loss: 0.017511412710288294 \n",
      "Epoch: 174 Loss: 0.010019441763276711 Validation Loss: 0.012652284531643 \n",
      "Epoch: 175 Loss: 0.009971325740341833 Validation Loss: 0.017464934421727137 \n",
      "Epoch: 176 Loss: 0.01002263513880512 Validation Loss: 0.012738665389851134 \n",
      "Epoch: 177 Loss: 0.009939395773031282 Validation Loss: 0.0173344625822529 \n",
      "Epoch: 178 Loss: 0.010057077493576554 Validation Loss: 0.012879817075014836 \n",
      "Epoch: 179 Loss: 0.009884702856752388 Validation Loss: 0.017314032365755964 \n",
      "Epoch: 180 Loss: 0.009960428764011573 Validation Loss: 0.012715744852389141 \n",
      "Epoch: 181 Loss: 0.009856293568441492 Validation Loss: 0.017366574940693068 \n",
      "Epoch: 182 Loss: 0.009876092202785125 Validation Loss: 0.012586593448264193 \n",
      "Epoch: 183 Loss: 0.009832865874726393 Validation Loss: 0.017278760359762717 \n",
      "Epoch: 184 Loss: 0.009890988123844585 Validation Loss: 0.012714249554045145 \n",
      "Epoch: 185 Loss: 0.009808726657701971 Validation Loss: 0.01716484851931959 \n",
      "Epoch: 186 Loss: 0.009929919766974913 Validation Loss: 0.01282922347932108 \n",
      "Epoch: 187 Loss: 0.009774695013542396 Validation Loss: 0.017187609635751305 \n",
      "Epoch: 188 Loss: 0.009849002098285438 Validation Loss: 0.012674072139449917 \n",
      "Epoch: 189 Loss: 0.009751875635628633 Validation Loss: 0.017245374413647666 \n",
      "Epoch: 190 Loss: 0.009771417388919094 Validation Loss: 0.012569846005398587 \n",
      "Epoch: 191 Loss: 0.00972319220860297 Validation Loss: 0.017150295013945865 \n",
      "Epoch: 192 Loss: 0.009779418888739544 Validation Loss: 0.012706260200801666 \n",
      "Epoch: 193 Loss: 0.009692576227867794 Validation Loss: 0.01701710311291691 \n",
      "Epoch: 194 Loss: 0.009814633216413828 Validation Loss: 0.012810352323313743 \n",
      "Epoch: 195 Loss: 0.009660307440149509 Validation Loss: 0.017052100804123484 \n",
      "Epoch: 196 Loss: 0.009735514088795992 Validation Loss: 0.012637276070192011 \n",
      "Epoch: 197 Loss: 0.009648675622669663 Validation Loss: 0.017141845550346466 \n",
      "Epoch: 198 Loss: 0.009662776678688758 Validation Loss: 0.012533032063083923 \n",
      "Epoch: 199 Loss: 0.009625142617087468 Validation Loss: 0.017042054136636443 \n",
      "Epoch: 200 Loss: 0.009680917239332043 Validation Loss: 0.012702938472333529 \n",
      "Epoch: 201 Loss: 0.00959542232470069 Validation Loss: 0.016885687554238984 \n",
      "Epoch: 202 Loss: 0.009727996350269021 Validation Loss: 0.012810223348226547 \n",
      "Epoch: 203 Loss: 0.009562763128230314 Validation Loss: 0.01694128342896554 \n",
      "Epoch: 204 Loss: 0.009635068977193701 Validation Loss: 0.012601755679305177 \n",
      "Epoch: 205 Loss: 0.009551740969494354 Validation Loss: 0.017045135844014254 \n",
      "Epoch: 206 Loss: 0.009554204420778437 Validation Loss: 0.012491793479613805 \n",
      "Epoch: 207 Loss: 0.009524146979310819 Validation Loss: 0.016922322943082362 \n",
      "Epoch: 208 Loss: 0.00957990593720756 Validation Loss: 0.012683201695446499 \n",
      "Epoch: 209 Loss: 0.009500205144505551 Validation Loss: 0.016759194126634815 \n",
      "Epoch: 210 Loss: 0.009643582796911758 Validation Loss: 0.012790107905344596 \n",
      "Epoch: 211 Loss: 0.00947677970604048 Validation Loss: 0.01683981046063225 \n",
      "Epoch: 212 Loss: 0.009550674251619656 Validation Loss: 0.012574719280220883 \n",
      "Epoch: 213 Loss: 0.009464596039194766 Validation Loss: 0.01694722386470597 \n",
      "Epoch: 214 Loss: 0.009460995786597464 Validation Loss: 0.012460348866093781 \n",
      "Epoch: 215 Loss: 0.009429610680886102 Validation Loss: 0.016811293309251282 \n",
      "Epoch: 216 Loss: 0.00948040679913241 Validation Loss: 0.012642150566613719 \n",
      "Epoch: 217 Loss: 0.009406071540698021 Validation Loss: 0.016640457346680647 \n",
      "Epoch: 218 Loss: 0.009554294882971597 Validation Loss: 0.012755407138057907 \n",
      "Epoch: 219 Loss: 0.009390356051338452 Validation Loss: 0.016725131265726053 \n",
      "Epoch: 220 Loss: 0.009471871879972182 Validation Loss: 0.012547894548245288 \n",
      "Epoch: 221 Loss: 0.00938178587762865 Validation Loss: 0.016848001794672423 \n",
      "Epoch: 222 Loss: 0.009376364033128944 Validation Loss: 0.01242038649606574 \n",
      "Epoch: 223 Loss: 0.009344996599911583 Validation Loss: 0.01671550806312268 \n",
      "Epoch: 224 Loss: 0.009387048143186581 Validation Loss: 0.01258825860800167 \n",
      "Epoch: 225 Loss: 0.009318904407964512 Validation Loss: 0.01652803818166776 \n",
      "Epoch: 226 Loss: 0.009472039057858185 Validation Loss: 0.012718061213369979 \n",
      "Epoch: 227 Loss: 0.009306775524796907 Validation Loss: 0.016606488087045953 \n",
      "Epoch: 228 Loss: 0.009396786640888468 Validation Loss: 0.012513769993469998 \n",
      "Epoch: 229 Loss: 0.009301160395625811 Validation Loss: 0.016746916493356266 \n",
      "Epoch: 230 Loss: 0.009293409437241806 Validation Loss: 0.012369563631279005 \n",
      "Epoch: 231 Loss: 0.009263461804276759 Validation Loss: 0.016618711250798 \n",
      "Epoch: 232 Loss: 0.009296837980249058 Validation Loss: 0.012523696460023504 \n",
      "Epoch: 233 Loss: 0.009235985435980256 Validation Loss: 0.01641909468456365 \n",
      "Epoch: 234 Loss: 0.009394444724789737 Validation Loss: 0.012669530661836568 \n",
      "Epoch: 235 Loss: 0.009228814617998116 Validation Loss: 0.01649305743602459 \n",
      "Epoch: 236 Loss: 0.009326568632643107 Validation Loss: 0.012471188157401293 \n",
      "Epoch: 237 Loss: 0.009224862450876614 Validation Loss: 0.016643986771536032 \n",
      "Epoch: 238 Loss: 0.00921518557487215 Validation Loss: 0.01231598638658057 \n",
      "Epoch: 239 Loss: 0.009184367681097592 Validation Loss: 0.016516409386376177 \n",
      "Epoch: 240 Loss: 0.009211439632045777 Validation Loss: 0.012453328332072796 \n",
      "Epoch: 241 Loss: 0.009155584056446137 Validation Loss: 0.016312732062771625 \n",
      "Epoch: 242 Loss: 0.009316872022112342 Validation Loss: 0.01260530157139871 \n",
      "Epoch: 243 Loss: 0.009153170576431885 Validation Loss: 0.016383763613480734 \n",
      "Epoch: 244 Loss: 0.00925587365454292 Validation Loss: 0.012415601572299277 \n",
      "Epoch: 245 Loss: 0.009151647457899703 Validation Loss: 0.016539113786515174 \n",
      "Epoch: 246 Loss: 0.009139792944457487 Validation Loss: 0.012256096075919895 \n",
      "Epoch: 247 Loss: 0.00910898046012878 Validation Loss: 0.01640976770783877 \n",
      "Epoch: 248 Loss: 0.009134406061742689 Validation Loss: 0.012383224440145986 \n",
      "Epoch: 249 Loss: 0.00908129624082687 Validation Loss: 0.016209584762905214 \n",
      "Epoch: 250 Loss: 0.009245476109426044 Validation Loss: 0.012531875257469793 \n",
      "Epoch: 251 Loss: 0.009081051896686348 Validation Loss: 0.016285016244660964 \n",
      "Epoch: 252 Loss: 0.009181053193081538 Validation Loss: 0.012341783550998627 \n",
      "Epoch: 253 Loss: 0.009080532246255517 Validation Loss: 0.016434572400039555 \n",
      "Epoch: 254 Loss: 0.009061067057629284 Validation Loss: 0.012185001398444667 \n",
      "Epoch: 255 Loss: 0.009034179060187103 Validation Loss: 0.01629193386739378 \n",
      "Epoch: 256 Loss: 0.009067168764736202 Validation Loss: 0.012318337612779173 \n",
      "Epoch: 257 Loss: 0.00901520881714712 Validation Loss: 0.01611109365203605 \n",
      "Epoch: 258 Loss: 0.009183906026678752 Validation Loss: 0.012450773521048978 \n",
      "Epoch: 259 Loss: 0.009015835575306292 Validation Loss: 0.01620848348378002 \n",
      "Epoch: 260 Loss: 0.009099331022914022 Validation Loss: 0.01224414957370035 \n",
      "Epoch: 261 Loss: 0.009013210139566886 Validation Loss: 0.016332326292242925 \n",
      "Epoch: 262 Loss: 0.00897796513532255 Validation Loss: 0.012106043193697846 \n",
      "Epoch: 263 Loss: 0.008959538481850257 Validation Loss: 0.01615887024795197 \n",
      "Epoch: 264 Loss: 0.009017556587226458 Validation Loss: 0.012268642044757675 \n",
      "Epoch: 265 Loss: 0.008958926893912042 Validation Loss: 0.01602641511188608 \n",
      "Epoch: 266 Loss: 0.009124544201777498 Validation Loss: 0.012354773136499575 \n",
      "Epoch: 267 Loss: 0.008957176376159953 Validation Loss: 0.016159610462018574 \n",
      "Epoch: 268 Loss: 0.009001051281477828 Validation Loss: 0.01210944125843619 \n",
      "Epoch: 269 Loss: 0.008949820049120216 Validation Loss: 0.016227120997910606 \n",
      "Epoch: 270 Loss: 0.008900480940799682 Validation Loss: 0.01203578635022621 \n",
      "Epoch: 271 Loss: 0.008896379988324498 Validation Loss: 0.016021582372259556 \n",
      "Epoch: 272 Loss: 0.009003869355799892 Validation Loss: 0.012252594254482854 \n",
      "Epoch: 273 Loss: 0.008908564973422598 Validation Loss: 0.015971010504536642 \n",
      "Epoch: 274 Loss: 0.009037552505359195 Validation Loss: 0.012217617330055082 \n",
      "Epoch: 275 Loss: 0.008903337915676544 Validation Loss: 0.01613211197571363 \n",
      "Epoch: 276 Loss: 0.008876958737919766 Validation Loss: 0.01194839790359221 \n",
      "Epoch: 277 Loss: 0.008876376700222925 Validation Loss: 0.016083646636748487 \n",
      "Epoch: 278 Loss: 0.00886173061322713 Validation Loss: 0.012035782228210258 \n",
      "Epoch: 279 Loss: 0.008859119035859621 Validation Loss: 0.01590700975252823 \n",
      "Epoch: 280 Loss: 0.009011242622789718 Validation Loss: 0.012236641248961375 \n",
      "Epoch: 281 Loss: 0.008858982052189612 Validation Loss: 0.015975554045505682 \n",
      "Epoch: 282 Loss: 0.008906359116598461 Validation Loss: 0.012015292569251325 \n",
      "Epoch: 283 Loss: 0.008855135471234107 Validation Loss: 0.016084046520512686 \n",
      "Epoch: 284 Loss: 0.008774028899996093 Validation Loss: 0.011899294183883524 \n",
      "Epoch: 285 Loss: 0.008787323521556445 Validation Loss: 0.01586526413987242 \n",
      "Epoch: 286 Loss: 0.008885413753281874 Validation Loss: 0.012122271865712745 \n",
      "Epoch: 287 Loss: 0.008813874457520892 Validation Loss: 0.015843687659809102 \n",
      "Epoch: 288 Loss: 0.008931739852592649 Validation Loss: 0.012099926072424827 \n",
      "Epoch: 289 Loss: 0.008826806096717956 Validation Loss: 0.01603000182518416 \n",
      "Epoch: 290 Loss: 0.008767273629575006 Validation Loss: 0.011857729170960084 \n",
      "Epoch: 291 Loss: 0.008772930577697482 Validation Loss: 0.015905850036308202 \n",
      "Epoch: 292 Loss: 0.008786657445233801 Validation Loss: 0.012003010977319113 \n",
      "Epoch: 293 Loss: 0.008768762187920323 Validation Loss: 0.01576242270933592 \n",
      "Epoch: 294 Loss: 0.008908665049175602 Validation Loss: 0.012122226099546026 \n",
      "Epoch: 295 Loss: 0.008778480902957322 Validation Loss: 0.015923085546049265 \n",
      "Epoch: 296 Loss: 0.008758598243684192 Validation Loss: 0.01185546503429081 \n",
      "Epoch: 297 Loss: 0.008753451868115675 Validation Loss: 0.01591119135220542 \n",
      "Epoch: 298 Loss: 0.008713249725926514 Validation Loss: 0.011923512530828566 \n",
      "Epoch: 299 Loss: 0.00872087114166888 Validation Loss: 0.01569777578953424 \n",
      "Epoch: 300 Loss: 0.008864254343419729 Validation Loss: 0.012109643015504278 \n",
      "Epoch: 301 Loss: 0.00873756825795187 Validation Loss: 0.01584003147300206 \n",
      "Epoch: 302 Loss: 0.008742655276080723 Validation Loss: 0.011856800016131994 \n",
      "Epoch: 303 Loss: 0.008731669793966092 Validation Loss: 0.015900650642310186 \n",
      "Epoch: 304 Loss: 0.00866551854539992 Validation Loss: 0.011885189924467734 \n",
      "Epoch: 305 Loss: 0.008683401634956046 Validation Loss: 0.015646919576862053 \n",
      "Epoch: 306 Loss: 0.00882469253498317 Validation Loss: 0.012090767085415429 \n",
      "Epoch: 307 Loss: 0.008704471378185146 Validation Loss: 0.015791714872053143 \n",
      "Epoch: 308 Loss: 0.008709669944884002 Validation Loss: 0.011840719076098157 \n",
      "Epoch: 309 Loss: 0.008699854496767197 Validation Loss: 0.015866848091427802 \n",
      "Epoch: 310 Loss: 0.008631003190331095 Validation Loss: 0.011880551011530413 \n",
      "Epoch: 311 Loss: 0.008653594923147035 Validation Loss: 0.015594805525841474 \n",
      "Epoch: 312 Loss: 0.008795732624755588 Validation Loss: 0.012071157072733867 \n",
      "Epoch: 313 Loss: 0.008681049183512358 Validation Loss: 0.015786878189722187 \n",
      "Epoch: 314 Loss: 0.008659037534507053 Validation Loss: 0.011810949072148361 \n",
      "Epoch: 315 Loss: 0.00865535997396187 Validation Loss: 0.01580105822254948 \n",
      "Epoch: 316 Loss: 0.00861503973025081 Validation Loss: 0.011909642101349528 \n",
      "Epoch: 317 Loss: 0.00863229235233177 Validation Loss: 0.01555154515268203 \n",
      "Epoch: 318 Loss: 0.008767621679665655 Validation Loss: 0.012038580404767182 \n",
      "Epoch: 319 Loss: 0.008665636410026852 Validation Loss: 0.01581947135600822 \n",
      "Epoch: 320 Loss: 0.00859129775621026 Validation Loss: 0.011792715367982005 \n",
      "Epoch: 321 Loss: 0.008595241970309826 Validation Loss: 0.015682191592994502 \n",
      "Epoch: 322 Loss: 0.008621002622265374 Validation Loss: 0.01196481741214042 \n",
      "Epoch: 323 Loss: 0.008610159343501504 Validation Loss: 0.01553496790600606 \n",
      "Epoch: 324 Loss: 0.008719066367744978 Validation Loss: 0.011982055900787448 \n",
      "Epoch: 325 Loss: 0.00864682207506566 Validation Loss: 0.015848658498967362 \n",
      "Epoch: 326 Loss: 0.008528529143506014 Validation Loss: 0.011803149708144 \n",
      "Epoch: 327 Loss: 0.008548473398627032 Validation Loss: 0.015552936590745543 \n",
      "Epoch: 328 Loss: 0.008642515533554463 Validation Loss: 0.012018270005732301 \n",
      "Epoch: 329 Loss: 0.00858596133856454 Validation Loss: 0.01557022987792399 \n",
      "Epoch: 330 Loss: 0.008645549913105314 Validation Loss: 0.011901153528546447 \n",
      "Epoch: 331 Loss: 0.008610279116588133 Validation Loss: 0.015826331750161633 \n",
      "Epoch: 332 Loss: 0.00849873145570763 Validation Loss: 0.011839850180477922 \n",
      "Epoch: 333 Loss: 0.008539117498438546 Validation Loss: 0.01546960560283192 \n",
      "Epoch: 334 Loss: 0.008667011241731417 Validation Loss: 0.012041474954590476 \n",
      "Epoch: 335 Loss: 0.008576245752834867 Validation Loss: 0.01567390935799807 \n",
      "Epoch: 336 Loss: 0.008550075892821404 Validation Loss: 0.011816886769495103 \n",
      "Epoch: 337 Loss: 0.008541928133613395 Validation Loss: 0.015701235016140933 \n",
      "Epoch: 338 Loss: 0.008514985328332315 Validation Loss: 0.011916860849468212 \n",
      "Epoch: 339 Loss: 0.008539902398127366 Validation Loss: 0.015442808533920133 \n",
      "Epoch: 340 Loss: 0.008650637153984729 Validation Loss: 0.012008386447006001 \n",
      "Epoch: 341 Loss: 0.008566034196860544 Validation Loss: 0.015773731613230514 \n",
      "Epoch: 342 Loss: 0.008452011194088544 Validation Loss: 0.011789954526424125 \n",
      "Epoch: 343 Loss: 0.00846703922362547 Validation Loss: 0.015502866147890228 \n",
      "Epoch: 344 Loss: 0.008538666048345203 Validation Loss: 0.011993460618962089 \n",
      "Epoch: 345 Loss: 0.008506990315839737 Validation Loss: 0.015476574118481561 \n",
      "Epoch: 346 Loss: 0.00857174340913662 Validation Loss: 0.01192220686171704 \n",
      "Epoch: 347 Loss: 0.008532351966098785 Validation Loss: 0.015773010932850443 \n",
      "Epoch: 348 Loss: 0.00842208499290354 Validation Loss: 0.011813179869678015 \n",
      "Epoch: 349 Loss: 0.008467047331026257 Validation Loss: 0.015431152252375792 \n",
      "Epoch: 350 Loss: 0.008578558867505004 Validation Loss: 0.01203986254609462 \n",
      "Epoch: 351 Loss: 0.00850000313463064 Validation Loss: 0.015590625351520433 \n",
      "Epoch: 352 Loss: 0.008488613966451652 Validation Loss: 0.01182461816804372 \n",
      "Epoch: 353 Loss: 0.008476544466219491 Validation Loss: 0.015688683916249356 \n",
      "Epoch: 354 Loss: 0.008421039446493877 Validation Loss: 0.011872701783290309 \n",
      "Epoch: 355 Loss: 0.008465806269903233 Validation Loss: 0.015377949340073551 \n",
      "Epoch: 356 Loss: 0.008572232787910418 Validation Loss: 0.012023752920299523 \n",
      "Epoch: 357 Loss: 0.00848596659286036 Validation Loss: 0.015696722974709847 \n",
      "Epoch: 358 Loss: 0.008390091331536825 Validation Loss: 0.011771772543156292 \n",
      "Epoch: 359 Loss: 0.008402266902301054 Validation Loss: 0.015501568401823908 \n",
      "Epoch: 360 Loss: 0.008445141908529219 Validation Loss: 0.011962155352749334 \n",
      "Epoch: 361 Loss: 0.00844017568874792 Validation Loss: 0.015394348482519967 \n",
      "Epoch: 362 Loss: 0.008511809777932401 Validation Loss: 0.011947579698935389 \n",
      "Epoch: 363 Loss: 0.008461721128872033 Validation Loss: 0.015738144166968396 \n",
      "Epoch: 364 Loss: 0.0083383958453934 Validation Loss: 0.011778705439336188 \n",
      "Epoch: 365 Loss: 0.008381502762134823 Validation Loss: 0.01539132956072026 \n",
      "Epoch: 366 Loss: 0.008478837544129854 Validation Loss: 0.012019292847205043 \n",
      "Epoch: 367 Loss: 0.008424677301159032 Validation Loss: 0.015487390382365249 \n",
      "Epoch: 368 Loss: 0.00844248303811154 Validation Loss: 0.011851034932740359 \n",
      "Epoch: 369 Loss: 0.008422721988467384 Validation Loss: 0.01570371134623708 \n",
      "Epoch: 370 Loss: 0.008324850306056111 Validation Loss: 0.01182173756514192 \n",
      "Epoch: 371 Loss: 0.008382498104264178 Validation Loss: 0.0153292171368423 \n",
      "Epoch: 372 Loss: 0.008488424133711476 Validation Loss: 0.01202580930949711 \n",
      "Epoch: 373 Loss: 0.00840896341154368 Validation Loss: 0.015596868113125661 \n",
      "Epoch: 374 Loss: 0.008351922230624888 Validation Loss: 0.01177418536819322 \n",
      "Epoch: 375 Loss: 0.008354433852155469 Validation Loss: 0.015555996187808107 \n",
      "Epoch: 376 Loss: 0.008342699256801674 Validation Loss: 0.011901777305906846 \n",
      "Epoch: 377 Loss: 0.008375284934308842 Validation Loss: 0.015318340855477057 \n",
      "Epoch: 378 Loss: 0.00845672216552874 Validation Loss: 0.011976498640109844 \n",
      "Epoch: 379 Loss: 0.008390150976316974 Validation Loss: 0.01568387962824479 \n",
      "Epoch: 380 Loss: 0.008269592435853457 Validation Loss: 0.011756171348486676 \n",
      "Epoch: 381 Loss: 0.008300599597489135 Validation Loss: 0.015385835358245325 \n",
      "Epoch: 382 Loss: 0.008370616448705905 Validation Loss: 0.011979423984104672 \n",
      "Epoch: 383 Loss: 0.008351768446336368 Validation Loss: 0.01537671547503348 \n",
      "Epoch: 384 Loss: 0.008396911175077997 Validation Loss: 0.011887915666281928 \n",
      "Epoch: 385 Loss: 0.00836559384612368 Validation Loss: 0.015707255404552648 \n",
      "Epoch: 386 Loss: 0.008236417341431738 Validation Loss: 0.011785513719359559 \n",
      "Epoch: 387 Loss: 0.00829500871187109 Validation Loss: 0.015298746236431682 \n",
      "Epoch: 388 Loss: 0.008397847113506282 Validation Loss: 0.012012643292806853 \n",
      "Epoch: 389 Loss: 0.008337367630327042 Validation Loss: 0.015493653447389736 \n",
      "Epoch: 390 Loss: 0.008321614728479322 Validation Loss: 0.011800569454852482 \n",
      "Epoch: 391 Loss: 0.008312396230094778 Validation Loss: 0.015619131003872964 \n",
      "Epoch: 392 Loss: 0.008238599875282956 Validation Loss: 0.011845220835366254 \n",
      "Epoch: 393 Loss: 0.008297996776394735 Validation Loss: 0.015260340966344531 \n",
      "Epoch: 394 Loss: 0.008391510890070186 Validation Loss: 0.011995019773913632 \n",
      "Epoch: 395 Loss: 0.008316784634582654 Validation Loss: 0.015602366482611015 \n",
      "Epoch: 396 Loss: 0.008227136065391022 Validation Loss: 0.011753753036480323 \n",
      "Epoch: 397 Loss: 0.008242247897884494 Validation Loss: 0.015438192073281839 \n",
      "Epoch: 398 Loss: 0.008266184022813237 Validation Loss: 0.011932275162912807 \n",
      "Epoch: 399 Loss: 0.008286278424386893 Validation Loss: 0.015283206634614714 \n",
      "Epoch: 400 Loss: 0.008350797507865758 Validation Loss: 0.01193048067600249 \n",
      "Epoch: 401 Loss: 0.008296963561110364 Validation Loss: 0.015680407705434617 \n",
      "Epoch: 402 Loss: 0.008156166110261294 Validation Loss: 0.011757252051519876 \n",
      "Epoch: 403 Loss: 0.008206154793450639 Validation Loss: 0.01528475204204119 \n",
      "Epoch: 404 Loss: 0.008300562740585557 Validation Loss: 0.011998730508640112 \n",
      "Epoch: 405 Loss: 0.008267614663292271 Validation Loss: 0.015379987542078226 \n",
      "Epoch: 406 Loss: 0.008292237560786 Validation Loss: 0.011846986652050853 \n",
      "Epoch: 407 Loss: 0.0082650629298584 Validation Loss: 0.015668037150853922 \n",
      "Epoch: 408 Loss: 0.008136840894952098 Validation Loss: 0.011799398034713611 \n",
      "Epoch: 409 Loss: 0.00820878638241954 Validation Loss: 0.015217742479191417 \n",
      "Epoch: 410 Loss: 0.008321079706274404 Validation Loss: 0.0120189009730733 \n",
      "Epoch: 411 Loss: 0.00824725713101122 Validation Loss: 0.01549490307135242 \n",
      "Epoch: 412 Loss: 0.008210006609928757 Validation Loss: 0.011784281240451649 \n",
      "Epoch: 413 Loss: 0.008200474111781366 Validation Loss: 0.015534095133845268 \n",
      "Epoch: 414 Loss: 0.008149104656904684 Validation Loss: 0.011865817848777271 \n",
      "Epoch: 415 Loss: 0.008213650344691693 Validation Loss: 0.015205586572263995 \n",
      "Epoch: 416 Loss: 0.00831213003897645 Validation Loss: 0.012002373705439858 \n",
      "Epoch: 417 Loss: 0.008222943469489406 Validation Loss: 0.015588784953438886 \n",
      "Epoch: 418 Loss: 0.008122286810327284 Validation Loss: 0.011750774784683464 \n",
      "Epoch: 419 Loss: 0.008140549224583054 Validation Loss: 0.015365128251368912 \n",
      "Epoch: 420 Loss: 0.008184314836811727 Validation Loss: 0.011960835625305323 \n",
      "Epoch: 421 Loss: 0.008205131103468287 Validation Loss: 0.01523530843975398 \n",
      "Epoch: 422 Loss: 0.008278476210987868 Validation Loss: 0.011949312113309197 \n",
      "Epoch: 423 Loss: 0.008201644317985916 Validation Loss: 0.01565831433750701 \n",
      "Epoch: 424 Loss: 0.008052588465134127 Validation Loss: 0.01175617221727286 \n",
      "Epoch: 425 Loss: 0.008107113388591727 Validation Loss: 0.015216968959659237 \n",
      "Epoch: 426 Loss: 0.008224122926697098 Validation Loss: 0.012036019227318045 \n",
      "Epoch: 427 Loss: 0.008187424923909658 Validation Loss: 0.015320999537984433 \n",
      "Epoch: 428 Loss: 0.008230262612728441 Validation Loss: 0.011886809614179915 \n",
      "Epoch: 429 Loss: 0.008173954103512614 Validation Loss: 0.015648791557010232 \n",
      "Epoch: 430 Loss: 0.008031330043145908 Validation Loss: 0.01179557915887862 \n",
      "Epoch: 431 Loss: 0.008104158287051896 Validation Loss: 0.015156696479142725 \n",
      "Epoch: 432 Loss: 0.008243571503596812 Validation Loss: 0.012062905702203561 \n",
      "Epoch: 433 Loss: 0.008167686392239037 Validation Loss: 0.015401198132388851 \n",
      "Epoch: 434 Loss: 0.0081741928539446 Validation Loss: 0.011850055497871416 \n",
      "Epoch: 435 Loss: 0.00812844186273109 Validation Loss: 0.015568534823120624 \n",
      "Epoch: 436 Loss: 0.008027817823076636 Validation Loss: 0.01183825881028882 \n",
      "Epoch: 437 Loss: 0.00809971640083842 Validation Loss: 0.015138004774798553 \n",
      "Epoch: 438 Loss: 0.00823738432408425 Validation Loss: 0.01206985863069422 \n",
      "Epoch: 439 Loss: 0.008142288559507507 Validation Loss: 0.015441787481665708 \n",
      "Epoch: 440 Loss: 0.008124039451794594 Validation Loss: 0.011829254789861523 \n",
      "Epoch: 441 Loss: 0.008089099691881976 Validation Loss: 0.01550221033989485 \n",
      "Epoch: 442 Loss: 0.008025378282827806 Validation Loss: 0.01187678205971271 \n",
      "Epoch: 443 Loss: 0.008093653847028997 Validation Loss: 0.01512888286774992 \n",
      "Epoch: 444 Loss: 0.008226521209822948 Validation Loss: 0.012072494647571208 \n",
      "Epoch: 445 Loss: 0.008121728857427601 Validation Loss: 0.015480564881923991 \n",
      "Epoch: 446 Loss: 0.008081842577206143 Validation Loss: 0.011815600359658177 \n",
      "Epoch: 447 Loss: 0.008056444570023734 Validation Loss: 0.015448346448794874 \n",
      "Epoch: 448 Loss: 0.008023472356846306 Validation Loss: 0.011916588802344887 \n",
      "Epoch: 449 Loss: 0.008081497023173406 Validation Loss: 0.015117353458337287 \n",
      "Epoch: 450 Loss: 0.00820528721115571 Validation Loss: 0.012063665154712525 \n",
      "Epoch: 451 Loss: 0.00810050528323149 Validation Loss: 0.015514531905926866 \n",
      "Epoch: 452 Loss: 0.008041052351859299 Validation Loss: 0.011810737222897775 \n",
      "Epoch: 453 Loss: 0.00802648296451651 Validation Loss: 0.015388590518951297 \n",
      "Epoch: 454 Loss: 0.008028849060989081 Validation Loss: 0.01196141788553972 \n",
      "Epoch: 455 Loss: 0.008066676191249176 Validation Loss: 0.015119107186719584 \n",
      "Epoch: 456 Loss: 0.008175344386810692 Validation Loss: 0.012042974465017953 \n",
      "Epoch: 457 Loss: 0.008078126443104065 Validation Loss: 0.01554582742290453 \n",
      "Epoch: 458 Loss: 0.007999235671811246 Validation Loss: 0.011811121820028607 \n",
      "Epoch: 459 Loss: 0.007998985317773172 Validation Loss: 0.01532115030678983 \n",
      "Epoch: 460 Loss: 0.008041374934092156 Validation Loss: 0.012011836790315438 \n",
      "Epoch: 461 Loss: 0.008052729377918033 Validation Loss: 0.015135016035098505 \n",
      "Epoch: 462 Loss: 0.008143659140817558 Validation Loss: 0.012013346093393114 \n",
      "Epoch: 463 Loss: 0.008058324140185478 Validation Loss: 0.01558319058970095 \n",
      "Epoch: 464 Loss: 0.007954863269806711 Validation Loss: 0.01181620322513333 \n",
      "Epoch: 465 Loss: 0.007971972304776604 Validation Loss: 0.01524082132937369 \n",
      "Epoch: 466 Loss: 0.008055283691055801 Validation Loss: 0.01206117950380579 \n",
      "Epoch: 467 Loss: 0.008038256001720402 Validation Loss: 0.015166054837203263 \n",
      "Epoch: 468 Loss: 0.008112772532622697 Validation Loss: 0.011978610275957343 \n",
      "Epoch: 469 Loss: 0.008042021612164022 Validation Loss: 0.015614989765754215 \n",
      "Epoch: 470 Loss: 0.007916717844110818 Validation Loss: 0.011832604557107256 \n",
      "Epoch: 471 Loss: 0.00794779897843944 Validation Loss: 0.015163750097401682 \n",
      "Epoch: 472 Loss: 0.00805957312778638 Validation Loss: 0.012090426322383515 \n",
      "Epoch: 473 Loss: 0.008021197930093099 Validation Loss: 0.015210215252647067 \n",
      "Epoch: 474 Loss: 0.008082411233677513 Validation Loss: 0.011953531994193604 \n",
      "Epoch: 475 Loss: 0.008022824260002039 Validation Loss: 0.015613344125739618 \n",
      "Epoch: 476 Loss: 0.007896750267032704 Validation Loss: 0.011857008903784015 \n",
      "Epoch: 477 Loss: 0.007930617331733971 Validation Loss: 0.015122485892324357 \n",
      "Epoch: 478 Loss: 0.008049553904917047 Validation Loss: 0.012099332819387972 \n",
      "Epoch: 479 Loss: 0.007999006010807047 Validation Loss: 0.015239839761522574 \n",
      "Epoch: 480 Loss: 0.008049685597497356 Validation Loss: 0.01194222693676686 \n",
      "Epoch: 481 Loss: 0.007997173375842602 Validation Loss: 0.015586969211780313 \n",
      "Epoch: 482 Loss: 0.007883812216582537 Validation Loss: 0.011875965274933589 \n",
      "Epoch: 483 Loss: 0.007916514617696576 Validation Loss: 0.015108581740464314 \n",
      "Epoch: 484 Loss: 0.008034724763737117 Validation Loss: 0.012105990408313977 \n",
      "Epoch: 485 Loss: 0.007977558205618141 Validation Loss: 0.015250657564373014 \n",
      "Epoch: 486 Loss: 0.008021955907025346 Validation Loss: 0.011936882204396464 \n",
      "Epoch: 487 Loss: 0.007974442225211084 Validation Loss: 0.015574987076447265 \n",
      "Epoch: 488 Loss: 0.00786479859670437 Validation Loss: 0.011885342496307343 \n",
      "Epoch: 489 Loss: 0.007898811007088887 Validation Loss: 0.01509283623284007 \n",
      "Epoch: 490 Loss: 0.008018664068063437 Validation Loss: 0.012115492010485606 \n",
      "Epoch: 491 Loss: 0.007958961092573824 Validation Loss: 0.015250736203696953 \n",
      "Epoch: 492 Loss: 0.008001437177422804 Validation Loss: 0.011934674532842728 \n",
      "Epoch: 493 Loss: 0.00795750653945493 Validation Loss: 0.01558031941794774 \n",
      "Epoch: 494 Loss: 0.007842859397146658 Validation Loss: 0.011890928189123332 \n",
      "Epoch: 495 Loss: 0.007877479295824054 Validation Loss: 0.01507367852456359 \n",
      "Epoch: 496 Loss: 0.007998448125608881 Validation Loss: 0.012120424820997476 \n",
      "Epoch: 497 Loss: 0.007940045367817701 Validation Loss: 0.015244946287743918 \n",
      "Epoch: 498 Loss: 0.007983156745723972 Validation Loss: 0.011936380463700637 \n",
      "Epoch: 499 Loss: 0.007941789104279609 Validation Loss: 0.015582651647162002 \n",
      "Epoch: 500 Loss: 0.007825641682892978 Validation Loss: 0.011896948152708467 \n"
     ]
    }
   ],
   "source": [
    "import nnet\n",
    "\n",
    "model = nnet.Sequential([\n",
    "    nnet.layers.Dense((13, 10), nnet.activation.Tanh),\n",
    "    nnet.layers.Dense((10, 8), nnet.activation.Tanh),\n",
    "    nnet.layers.Dense((8, 2), nnet.activation.Sigmoid)\n",
    "])\n",
    "\n",
    "model.fit(X_train, Y_train, 500, nnet.loss.MeanSquaredError, nnet.optimizers.RMSProp(), X_val=X_test, Y_val=Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09546488877566717"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test model accuracy using Mean Absolute Error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "mean_absolute_error(Y_test, y_pred.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actual testing\n",
    "def test_prediction(index):\n",
    "    y_pred = model.predict(np.array([X_test[index]]))\n",
    "    y_true = np.array([Y_test[index]])\n",
    "    \n",
    "    print('Prediction', y_scaler.inverse_transform(y_pred.T))\n",
    "    print('Actual', y_scaler.inverse_transform(y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction [[ 1.03892827 25.63614434]]\n",
      "Actual [[ 1.0433 24.5   ]]\n"
     ]
    }
   ],
   "source": [
    "test_prediction(18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction [[ 1.05549184 20.44400959]]\n",
      "Actual [[ 1.0646 15.    ]]\n"
     ]
    }
   ],
   "source": [
    "test_prediction(19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction [[ 1.0381298  26.21384877]]\n",
      "Actual [[ 1.0418 25.2   ]]\n"
     ]
    }
   ],
   "source": [
    "test_prediction(27)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3e248e8823122d6c7234371ee991cc4810791faba3b9f400ab196a38c557164b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
