{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Density</th>\n",
       "      <th>BodyFat</th>\n",
       "      <th>Age</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height</th>\n",
       "      <th>Neck</th>\n",
       "      <th>Chest</th>\n",
       "      <th>Abdomen</th>\n",
       "      <th>Hip</th>\n",
       "      <th>Thigh</th>\n",
       "      <th>Knee</th>\n",
       "      <th>Ankle</th>\n",
       "      <th>Biceps</th>\n",
       "      <th>Forearm</th>\n",
       "      <th>Wrist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0708</td>\n",
       "      <td>12.3</td>\n",
       "      <td>23</td>\n",
       "      <td>154.25</td>\n",
       "      <td>67.75</td>\n",
       "      <td>36.2</td>\n",
       "      <td>93.1</td>\n",
       "      <td>85.2</td>\n",
       "      <td>94.5</td>\n",
       "      <td>59.0</td>\n",
       "      <td>37.3</td>\n",
       "      <td>21.9</td>\n",
       "      <td>32.0</td>\n",
       "      <td>27.4</td>\n",
       "      <td>17.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0853</td>\n",
       "      <td>6.1</td>\n",
       "      <td>22</td>\n",
       "      <td>173.25</td>\n",
       "      <td>72.25</td>\n",
       "      <td>38.5</td>\n",
       "      <td>93.6</td>\n",
       "      <td>83.0</td>\n",
       "      <td>98.7</td>\n",
       "      <td>58.7</td>\n",
       "      <td>37.3</td>\n",
       "      <td>23.4</td>\n",
       "      <td>30.5</td>\n",
       "      <td>28.9</td>\n",
       "      <td>18.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0414</td>\n",
       "      <td>25.3</td>\n",
       "      <td>22</td>\n",
       "      <td>154.00</td>\n",
       "      <td>66.25</td>\n",
       "      <td>34.0</td>\n",
       "      <td>95.8</td>\n",
       "      <td>87.9</td>\n",
       "      <td>99.2</td>\n",
       "      <td>59.6</td>\n",
       "      <td>38.9</td>\n",
       "      <td>24.0</td>\n",
       "      <td>28.8</td>\n",
       "      <td>25.2</td>\n",
       "      <td>16.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0751</td>\n",
       "      <td>10.4</td>\n",
       "      <td>26</td>\n",
       "      <td>184.75</td>\n",
       "      <td>72.25</td>\n",
       "      <td>37.4</td>\n",
       "      <td>101.8</td>\n",
       "      <td>86.4</td>\n",
       "      <td>101.2</td>\n",
       "      <td>60.1</td>\n",
       "      <td>37.3</td>\n",
       "      <td>22.8</td>\n",
       "      <td>32.4</td>\n",
       "      <td>29.4</td>\n",
       "      <td>18.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0340</td>\n",
       "      <td>28.7</td>\n",
       "      <td>24</td>\n",
       "      <td>184.25</td>\n",
       "      <td>71.25</td>\n",
       "      <td>34.4</td>\n",
       "      <td>97.3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>101.9</td>\n",
       "      <td>63.2</td>\n",
       "      <td>42.2</td>\n",
       "      <td>24.0</td>\n",
       "      <td>32.2</td>\n",
       "      <td>27.7</td>\n",
       "      <td>17.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Density  BodyFat  Age  Weight  Height  Neck  Chest  Abdomen    Hip  Thigh  \\\n",
       "0   1.0708     12.3   23  154.25   67.75  36.2   93.1     85.2   94.5   59.0   \n",
       "1   1.0853      6.1   22  173.25   72.25  38.5   93.6     83.0   98.7   58.7   \n",
       "2   1.0414     25.3   22  154.00   66.25  34.0   95.8     87.9   99.2   59.6   \n",
       "3   1.0751     10.4   26  184.75   72.25  37.4  101.8     86.4  101.2   60.1   \n",
       "4   1.0340     28.7   24  184.25   71.25  34.4   97.3    100.0  101.9   63.2   \n",
       "\n",
       "   Knee  Ankle  Biceps  Forearm  Wrist  \n",
       "0  37.3   21.9    32.0     27.4   17.1  \n",
       "1  37.3   23.4    30.5     28.9   18.2  \n",
       "2  38.9   24.0    28.8     25.2   16.6  \n",
       "3  37.3   22.8    32.4     29.4   18.2  \n",
       "4  42.2   24.0    32.2     27.7   17.7  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "# define dataset\n",
    "df = pd.read_csv('bodyfat_dataset.csv')\n",
    "df.sample(frac = 1) # shuffle\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(252, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = df.loc[:, ['Density', 'BodyFat']]\n",
    "labels = np.array(labels)\n",
    "\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height</th>\n",
       "      <th>Neck</th>\n",
       "      <th>Chest</th>\n",
       "      <th>Abdomen</th>\n",
       "      <th>Hip</th>\n",
       "      <th>Thigh</th>\n",
       "      <th>Knee</th>\n",
       "      <th>Ankle</th>\n",
       "      <th>Biceps</th>\n",
       "      <th>Forearm</th>\n",
       "      <th>Wrist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>154.25</td>\n",
       "      <td>67.75</td>\n",
       "      <td>36.2</td>\n",
       "      <td>93.1</td>\n",
       "      <td>85.2</td>\n",
       "      <td>94.5</td>\n",
       "      <td>59.0</td>\n",
       "      <td>37.3</td>\n",
       "      <td>21.9</td>\n",
       "      <td>32.0</td>\n",
       "      <td>27.4</td>\n",
       "      <td>17.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>173.25</td>\n",
       "      <td>72.25</td>\n",
       "      <td>38.5</td>\n",
       "      <td>93.6</td>\n",
       "      <td>83.0</td>\n",
       "      <td>98.7</td>\n",
       "      <td>58.7</td>\n",
       "      <td>37.3</td>\n",
       "      <td>23.4</td>\n",
       "      <td>30.5</td>\n",
       "      <td>28.9</td>\n",
       "      <td>18.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>154.00</td>\n",
       "      <td>66.25</td>\n",
       "      <td>34.0</td>\n",
       "      <td>95.8</td>\n",
       "      <td>87.9</td>\n",
       "      <td>99.2</td>\n",
       "      <td>59.6</td>\n",
       "      <td>38.9</td>\n",
       "      <td>24.0</td>\n",
       "      <td>28.8</td>\n",
       "      <td>25.2</td>\n",
       "      <td>16.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26</td>\n",
       "      <td>184.75</td>\n",
       "      <td>72.25</td>\n",
       "      <td>37.4</td>\n",
       "      <td>101.8</td>\n",
       "      <td>86.4</td>\n",
       "      <td>101.2</td>\n",
       "      <td>60.1</td>\n",
       "      <td>37.3</td>\n",
       "      <td>22.8</td>\n",
       "      <td>32.4</td>\n",
       "      <td>29.4</td>\n",
       "      <td>18.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>184.25</td>\n",
       "      <td>71.25</td>\n",
       "      <td>34.4</td>\n",
       "      <td>97.3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>101.9</td>\n",
       "      <td>63.2</td>\n",
       "      <td>42.2</td>\n",
       "      <td>24.0</td>\n",
       "      <td>32.2</td>\n",
       "      <td>27.7</td>\n",
       "      <td>17.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Weight  Height  Neck  Chest  Abdomen    Hip  Thigh  Knee  Ankle  \\\n",
       "0   23  154.25   67.75  36.2   93.1     85.2   94.5   59.0  37.3   21.9   \n",
       "1   22  173.25   72.25  38.5   93.6     83.0   98.7   58.7  37.3   23.4   \n",
       "2   22  154.00   66.25  34.0   95.8     87.9   99.2   59.6  38.9   24.0   \n",
       "3   26  184.75   72.25  37.4  101.8     86.4  101.2   60.1  37.3   22.8   \n",
       "4   24  184.25   71.25  34.4   97.3    100.0  101.9   63.2  42.2   24.0   \n",
       "\n",
       "   Biceps  Forearm  Wrist  \n",
       "0    32.0     27.4   17.1  \n",
       "1    30.5     28.9   18.2  \n",
       "2    28.8     25.2   16.6  \n",
       "3    32.4     29.4   18.2  \n",
       "4    32.2     27.7   17.7  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop the data labels\n",
    "df = df.drop('Density', axis=1)\n",
    "df = df.drop('BodyFat', axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(252, 13)\n",
      "(252, 2)\n"
     ]
    }
   ],
   "source": [
    "# scale data\n",
    "data = np.array(df)\n",
    "\n",
    "x_scaler = MinMaxScaler()\n",
    "y_scaler = MinMaxScaler()\n",
    "\n",
    "X = x_scaler.fit_transform(data)\n",
    "Y = y_scaler.fit_transform(labels)\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 13)\n",
      "(200, 2)\n",
      "(52, 13)\n",
      "(52, 2)\n"
     ]
    }
   ],
   "source": [
    "X_train = X[:200]\n",
    "Y_train = Y[:200]\n",
    "\n",
    "X_test = X[-52:]\n",
    "Y_test = Y[-52:]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Loss: 0.1373403546007454 Validation Loss: 0.14511676921130337 \n",
      "Epoch: 2 Loss: 0.04489576286010153 Validation Loss: 0.05449298069423191 \n",
      "Epoch: 3 Loss: 0.031935401495590335 Validation Loss: 0.03580132541762394 \n",
      "Epoch: 4 Loss: 0.028975131398887754 Validation Loss: 0.03140282511322538 \n",
      "Epoch: 5 Loss: 0.027840531577243654 Validation Loss: 0.03139387026615961 \n",
      "Epoch: 6 Loss: 0.02694237939948709 Validation Loss: 0.029011428386291782 \n",
      "Epoch: 7 Loss: 0.02784953012840203 Validation Loss: 0.03142821633790105 \n",
      "Epoch: 8 Loss: 0.02528105912955211 Validation Loss: 0.027491345328163528 \n",
      "Epoch: 9 Loss: 0.02548451870152805 Validation Loss: 0.027827247243212838 \n",
      "Epoch: 10 Loss: 0.02339144483291005 Validation Loss: 0.025686763906227712 \n",
      "Epoch: 11 Loss: 0.02335147787776244 Validation Loss: 0.02484544559790047 \n",
      "Epoch: 12 Loss: 0.022150389828716425 Validation Loss: 0.024673165908731906 \n",
      "Epoch: 13 Loss: 0.02227637699825706 Validation Loss: 0.02335644691158499 \n",
      "Epoch: 14 Loss: 0.02139883116922126 Validation Loss: 0.02427583455106349 \n",
      "Epoch: 15 Loss: 0.021739853343663764 Validation Loss: 0.022537792502450398 \n",
      "Epoch: 16 Loss: 0.02087538039916779 Validation Loss: 0.024127560226456107 \n",
      "Epoch: 17 Loss: 0.021316380731410182 Validation Loss: 0.02188355099252963 \n",
      "Epoch: 18 Loss: 0.020336841492474722 Validation Loss: 0.023858956175925452 \n",
      "Epoch: 19 Loss: 0.02073314432134994 Validation Loss: 0.021122587997201084 \n",
      "Epoch: 20 Loss: 0.019752778421087084 Validation Loss: 0.023443360156446078 \n",
      "Epoch: 21 Loss: 0.02008578470512558 Validation Loss: 0.020354328645427282 \n",
      "Epoch: 22 Loss: 0.019222703826199266 Validation Loss: 0.023055509565371193 \n",
      "Epoch: 23 Loss: 0.019542723130288767 Validation Loss: 0.019720255898471647 \n",
      "Epoch: 24 Loss: 0.01879605514013303 Validation Loss: 0.022780855600105693 \n",
      "Epoch: 25 Loss: 0.019134487426441308 Validation Loss: 0.019226967003535437 \n",
      "Epoch: 26 Loss: 0.01845235194878039 Validation Loss: 0.022586562206732084 \n",
      "Epoch: 27 Loss: 0.018802542180433583 Validation Loss: 0.018816957456029505 \n",
      "Epoch: 28 Loss: 0.01814211500533329 Validation Loss: 0.02239343923496987 \n",
      "Epoch: 29 Loss: 0.01847681232417492 Validation Loss: 0.018434137680178552 \n",
      "Epoch: 30 Loss: 0.01783055755898204 Validation Loss: 0.022152911612044572 \n",
      "Epoch: 31 Loss: 0.018131169367876055 Validation Loss: 0.01805882965987318 \n",
      "Epoch: 32 Loss: 0.017517631434701357 Validation Loss: 0.021876890151335836 \n",
      "Epoch: 33 Loss: 0.017786246692881473 Validation Loss: 0.01770410447858191 \n",
      "Epoch: 34 Loss: 0.017221634517495355 Validation Loss: 0.021604467777323347 \n",
      "Epoch: 35 Loss: 0.017470106852458197 Validation Loss: 0.01738599503220319 \n",
      "Epoch: 36 Loss: 0.016954292365314993 Validation Loss: 0.0213590053026802 \n",
      "Epoch: 37 Loss: 0.01719059149367188 Validation Loss: 0.017106657025466616 \n",
      "Epoch: 38 Loss: 0.016712319843594572 Validation Loss: 0.02113619411039804 \n",
      "Epoch: 39 Loss: 0.016936338388350528 Validation Loss: 0.01685732924960907 \n",
      "Epoch: 40 Loss: 0.016483949915265722 Validation Loss: 0.02091776587490802 \n",
      "Epoch: 41 Loss: 0.016691479222554317 Validation Loss: 0.01662759217521929 \n",
      "Epoch: 42 Loss: 0.016259791735025828 Validation Loss: 0.020691126826099984 \n",
      "Epoch: 43 Loss: 0.016448663576877354 Validation Loss: 0.016412207455630344 \n",
      "Epoch: 44 Loss: 0.01603880030036057 Validation Loss: 0.020458701251643657 \n",
      "Epoch: 45 Loss: 0.016211487002508886 Validation Loss: 0.016211941847615416 \n",
      "Epoch: 46 Loss: 0.015825944670960056 Validation Loss: 0.02023243217897818 \n",
      "Epoch: 47 Loss: 0.015987511837950198 Validation Loss: 0.016029670576129994 \n",
      "Epoch: 48 Loss: 0.015625948011470183 Validation Loss: 0.020022385760820185 \n",
      "Epoch: 49 Loss: 0.0157806556452104 Validation Loss: 0.015866541275998045 \n",
      "Epoch: 50 Loss: 0.01543940945446491 Validation Loss: 0.019830493324727524 \n",
      "Epoch: 51 Loss: 0.015589101319378846 Validation Loss: 0.015720987378207284 \n",
      "Epoch: 52 Loss: 0.01526343927917962 Validation Loss: 0.019652491011023846 \n",
      "Epoch: 53 Loss: 0.015408290151056984 Validation Loss: 0.015590006802132307 \n",
      "Epoch: 54 Loss: 0.015094871443948358 Validation Loss: 0.019484017651488765 \n",
      "Epoch: 55 Loss: 0.015235146030631459 Validation Loss: 0.015471004672616799 \n",
      "Epoch: 56 Loss: 0.014932829066664781 Validation Loss: 0.0193249438263399 \n",
      "Epoch: 57 Loss: 0.01506989192552478 Validation Loss: 0.015362756990231173 \n",
      "Epoch: 58 Loss: 0.014778663795218057 Validation Loss: 0.019178743263615287 \n",
      "Epoch: 59 Loss: 0.014914530118974836 Validation Loss: 0.015264996330512589 \n",
      "Epoch: 60 Loss: 0.014633908637305395 Validation Loss: 0.0190485541052599 \n",
      "Epoch: 61 Loss: 0.014770090464507512 Validation Loss: 0.015177325428401302 \n",
      "Epoch: 62 Loss: 0.014498480791371005 Validation Loss: 0.018934113925703787 \n",
      "Epoch: 63 Loss: 0.01463533991462481 Validation Loss: 0.015098551662429495 \n",
      "Epoch: 64 Loss: 0.014370655874883072 Validation Loss: 0.01883208583511965 \n",
      "Epoch: 65 Loss: 0.014507772139866155 Validation Loss: 0.015026934358454584 \n",
      "Epoch: 66 Loss: 0.0142484917492333 Validation Loss: 0.01873885618116946 \n",
      "Epoch: 67 Loss: 0.014385570698909248 Validation Loss: 0.01496099322320232 \n",
      "Epoch: 68 Loss: 0.014131177852693801 Validation Loss: 0.018652907601423727 \n",
      "Epoch: 69 Loss: 0.014268604632705134 Validation Loss: 0.014900073928037584 \n",
      "Epoch: 70 Loss: 0.01401909574323 Validation Loss: 0.018574739192803 \n",
      "Epoch: 71 Loss: 0.01415769886057241 Validation Loss: 0.014844163865879044 \n",
      "Epoch: 72 Loss: 0.013912765216558622 Validation Loss: 0.018504904771538936 \n",
      "Epoch: 73 Loss: 0.014053162346847677 Validation Loss: 0.014793220869910438 \n",
      "Epoch: 74 Loss: 0.013811871593527592 Validation Loss: 0.018442393027325806 \n",
      "Epoch: 75 Loss: 0.013954092282049212 Validation Loss: 0.014746700553644358 \n",
      "Epoch: 76 Loss: 0.013715289000998845 Validation Loss: 0.01838485557840228 \n",
      "Epoch: 77 Loss: 0.01385899067010374 Validation Loss: 0.014703688227597616 \n",
      "Epoch: 78 Loss: 0.013621927599295303 Validation Loss: 0.018330203188398675 \n",
      "Epoch: 79 Loss: 0.01376691091936894 Validation Loss: 0.014663431860043237 \n",
      "Epoch: 80 Loss: 0.013531467537114103 Validation Loss: 0.018277850634593824 \n",
      "Epoch: 81 Loss: 0.01367794331728191 Validation Loss: 0.014625707973264863 \n",
      "Epoch: 82 Loss: 0.013444272063129606 Validation Loss: 0.018228447077628482 \n",
      "Epoch: 83 Loss: 0.013592643779517487 Validation Loss: 0.014590666211798702 \n",
      "Epoch: 84 Loss: 0.01336067811091016 Validation Loss: 0.018182564396873255 \n",
      "Epoch: 85 Loss: 0.013511111589559572 Validation Loss: 0.014558351995382045 \n",
      "Epoch: 86 Loss: 0.013280451132853562 Validation Loss: 0.018139767526941006 \n",
      "Epoch: 87 Loss: 0.013432665055500177 Validation Loss: 0.014528402897682176 \n",
      "Epoch: 88 Loss: 0.01320290083057943 Validation Loss: 0.018098882992897938 \n",
      "Epoch: 89 Loss: 0.01335632692274323 Validation Loss: 0.014500187699750183 \n",
      "Epoch: 90 Loss: 0.013127420571708468 Validation Loss: 0.01805897166586491 \n",
      "Epoch: 91 Loss: 0.013281511821195928 Validation Loss: 0.014473195500675051 \n",
      "Epoch: 92 Loss: 0.013053846646094165 Validation Loss: 0.01801992366339515 \n",
      "Epoch: 93 Loss: 0.013208232146621727 Validation Loss: 0.014447269513691418 \n",
      "Epoch: 94 Loss: 0.012982337970470083 Validation Loss: 0.017982188607259017 \n",
      "Epoch: 95 Loss: 0.013136753191077828 Validation Loss: 0.014422506630597702 \n",
      "Epoch: 96 Loss: 0.012913013048046701 Validation Loss: 0.01794610185993966 \n",
      "Epoch: 97 Loss: 0.013067170438985682 Validation Loss: 0.014399002758842233 \n",
      "Epoch: 98 Loss: 0.012845749738946644 Validation Loss: 0.017911530139173775 \n",
      "Epoch: 99 Loss: 0.01299931570136876 Validation Loss: 0.014376712655771846 \n",
      "Epoch: 100 Loss: 0.012780279118708316 Validation Loss: 0.017878053020288838 \n",
      "Epoch: 101 Loss: 0.012932957416111217 Validation Loss: 0.014355496981465708 \n",
      "Epoch: 102 Loss: 0.012716385411735236 Validation Loss: 0.01784533476793473 \n",
      "Epoch: 103 Loss: 0.01286799235869728 Validation Loss: 0.014335230690943232 \n",
      "Epoch: 104 Loss: 0.012653984433133673 Validation Loss: 0.017813278943551645 \n",
      "Epoch: 105 Loss: 0.012804438224992887 Validation Loss: 0.014315838316504804 \n",
      "Epoch: 106 Loss: 0.012593045648129133 Validation Loss: 0.01778190091236295 \n",
      "Epoch: 107 Loss: 0.012742298718888797 Validation Loss: 0.01429724653643458 \n",
      "Epoch: 108 Loss: 0.012533488502779093 Validation Loss: 0.017751146681190638 \n",
      "Epoch: 109 Loss: 0.012681479873157193 Validation Loss: 0.014279334410638401 \n",
      "Epoch: 110 Loss: 0.012475168540297652 Validation Loss: 0.017720862132705333 \n",
      "Epoch: 111 Loss: 0.012621831563989789 Validation Loss: 0.014261940456144163 \n",
      "Epoch: 112 Loss: 0.012417943820202887 Validation Loss: 0.01769089791213466 \n",
      "Epoch: 113 Loss: 0.012563240611732262 Validation Loss: 0.014244910565300315 \n",
      "Epoch: 114 Loss: 0.012361733449331886 Validation Loss: 0.017661197872400655 \n",
      "Epoch: 115 Loss: 0.012505669878367051 Validation Loss: 0.014228132090680098 \n",
      "Epoch: 116 Loss: 0.012306511306142041 Validation Loss: 0.01763177497139299 \n",
      "Epoch: 117 Loss: 0.012449119401635744 Validation Loss: 0.014211526490600023 \n",
      "Epoch: 118 Loss: 0.012252257077417738 Validation Loss: 0.017602616614024198 \n",
      "Epoch: 119 Loss: 0.012393568259177314 Validation Loss: 0.014195022196190198 \n",
      "Epoch: 120 Loss: 0.012198922289645643 Validation Loss: 0.01757362301732927 \n",
      "Epoch: 121 Loss: 0.012338957775471395 Validation Loss: 0.014178544394893631 \n",
      "Epoch: 122 Loss: 0.012146438374631257 Validation Loss: 0.017544629768502754 \n",
      "Epoch: 123 Loss: 0.012285218937482361 Validation Loss: 0.014162029770119116 \n",
      "Epoch: 124 Loss: 0.01209474596944926 Validation Loss: 0.01751548088066677 \n",
      "Epoch: 125 Loss: 0.01223230380846784 Validation Loss: 0.014145441949425788 \n",
      "Epoch: 126 Loss: 0.012043811443293456 Validation Loss: 0.017486085448245706 \n",
      "Epoch: 127 Loss: 0.012180190497329 Validation Loss: 0.014128767033266206 \n",
      "Epoch: 128 Loss: 0.011993620075643778 Validation Loss: 0.01745642206765977 \n",
      "Epoch: 129 Loss: 0.01212886710890791 Validation Loss: 0.014111996460841979 \n",
      "Epoch: 130 Loss: 0.01194416048693785 Validation Loss: 0.017426507312276792 \n",
      "Epoch: 131 Loss: 0.012078317505604397 Validation Loss: 0.014095115395374955 \n",
      "Epoch: 132 Loss: 0.011895417116216783 Validation Loss: 0.017396366128974092 \n",
      "Epoch: 133 Loss: 0.012028520758440648 Validation Loss: 0.0140781029462601 \n",
      "Epoch: 134 Loss: 0.011847373315907407 Validation Loss: 0.017366021892012314 \n",
      "Epoch: 135 Loss: 0.011979458584623707 Validation Loss: 0.01406093878476589 \n",
      "Epoch: 136 Loss: 0.011800016686652481 Validation Loss: 0.017335497169050584 \n",
      "Epoch: 137 Loss: 0.011931119792288149 Validation Loss: 0.014043608673198564 \n",
      "Epoch: 138 Loss: 0.011753339569611781 Validation Loss: 0.017304811871361164 \n",
      "Epoch: 139 Loss: 0.011883497869987818 Validation Loss: 0.01402610557463231 \n",
      "Epoch: 140 Loss: 0.011707335310623852 Validation Loss: 0.01727397718655884 \n",
      "Epoch: 141 Loss: 0.01183658624628848 Validation Loss: 0.01400842817946101 \n",
      "Epoch: 142 Loss: 0.011661995318119837 Validation Loss: 0.017242992129315658 \n",
      "Epoch: 143 Loss: 0.011790376933295692 Validation Loss: 0.013990580720685087 \n",
      "Epoch: 144 Loss: 0.011617309814776608 Validation Loss: 0.01721184698945136 \n",
      "Epoch: 145 Loss: 0.01174486333214742 Validation Loss: 0.01397257601346582 \n",
      "Epoch: 146 Loss: 0.011573270684350892 Validation Loss: 0.017180531036917843 \n",
      "Epoch: 147 Loss: 0.01170004361970444 Validation Loss: 0.013954440601118796 \n",
      "Epoch: 148 Loss: 0.011529873180102696 Validation Loss: 0.01714903969993183 \n",
      "Epoch: 149 Loss: 0.011655921469067479 Validation Loss: 0.013936219761207765 \n",
      "Epoch: 150 Loss: 0.011487115322028623 Validation Loss: 0.01711738074665978 \n",
      "Epoch: 151 Loss: 0.011612504019089833 Validation Loss: 0.013917980867893467 \n",
      "Epoch: 152 Loss: 0.011444996412539812 Validation Loss: 0.0170855844526371 \n",
      "Epoch: 153 Loss: 0.011569798635145267 Validation Loss: 0.013899813415611232 \n",
      "Epoch: 154 Loss: 0.011403516382431396 Validation Loss: 0.017053723758367077 \n",
      "Epoch: 155 Loss: 0.011527808361548765 Validation Loss: 0.013881820475132069 \n",
      "Epoch: 156 Loss: 0.011362675942358746 Validation Loss: 0.017021944788219792 \n",
      "Epoch: 157 Loss: 0.011486523742680093 Validation Loss: 0.01386409160003872 \n",
      "Epoch: 158 Loss: 0.011322476402822114 Validation Loss: 0.01699049461730797 \n",
      "Epoch: 159 Loss: 0.011445911532036534 Validation Loss: 0.013846652876326835 \n",
      "Epoch: 160 Loss: 0.011282919761395368 Validation Loss: 0.016959714354385227 \n",
      "Epoch: 161 Loss: 0.011405912494347121 Validation Loss: 0.013829422305117613 \n",
      "Epoch: 162 Loss: 0.01124401272015852 Validation Loss: 0.01692996653609349 \n",
      "Epoch: 163 Loss: 0.011366468068362565 Validation Loss: 0.0138122340196039 \n",
      "Epoch: 164 Loss: 0.011205775004275506 Validation Loss: 0.016901522322567065 \n",
      "Epoch: 165 Loss: 0.011327566124356803 Validation Loss: 0.013794943793137714 \n",
      "Epoch: 166 Loss: 0.011168238910639627 Validation Loss: 0.016874489795415074 \n",
      "Epoch: 167 Loss: 0.011289249323108312 Validation Loss: 0.013777513272196812 \n",
      "Epoch: 168 Loss: 0.011131424672316828 Validation Loss: 0.01684881204457232 \n",
      "Epoch: 169 Loss: 0.011251561289787078 Validation Loss: 0.013759989305265678 \n",
      "Epoch: 170 Loss: 0.01109530697477797 Validation Loss: 0.01682429806589722 \n",
      "Epoch: 171 Loss: 0.011214491882638521 Validation Loss: 0.013742429931071887 \n",
      "Epoch: 172 Loss: 0.011059812728401144 Validation Loss: 0.01680068120778331 \n",
      "Epoch: 173 Loss: 0.011177983604637681 Validation Loss: 0.013724865593918785 \n",
      "Epoch: 174 Loss: 0.011024859498824691 Validation Loss: 0.016777708746371724 \n",
      "Epoch: 175 Loss: 0.011141982016901631 Validation Loss: 0.013707313122254199 \n",
      "Epoch: 176 Loss: 0.010990396768744037 Validation Loss: 0.016755215499702335 \n",
      "Epoch: 177 Loss: 0.011106470108212689 Validation Loss: 0.013689803013187183 \n",
      "Epoch: 178 Loss: 0.010956412637731491 Validation Loss: 0.0167331312277831 \n",
      "Epoch: 179 Loss: 0.011071458301142416 Validation Loss: 0.013672385473068701 \n",
      "Epoch: 180 Loss: 0.010922909004644535 Validation Loss: 0.016711432179054315 \n",
      "Epoch: 181 Loss: 0.011036952801198319 Validation Loss: 0.013655115865380759 \n",
      "Epoch: 182 Loss: 0.010889876421385437 Validation Loss: 0.016690091941844086 \n",
      "Epoch: 183 Loss: 0.01100293851366911 Validation Loss: 0.013638040886021763 \n",
      "Epoch: 184 Loss: 0.010857290527547107 Validation Loss: 0.016669070434024085 \n",
      "Epoch: 185 Loss: 0.010969387491713606 Validation Loss: 0.013621198950268067 \n",
      "Epoch: 186 Loss: 0.010825125147320348 Validation Loss: 0.0166483334214789 \n",
      "Epoch: 187 Loss: 0.010936276435793592 Validation Loss: 0.013604629477646034 \n",
      "Epoch: 188 Loss: 0.010793363590919933 Validation Loss: 0.016627870665452186 \n",
      "Epoch: 189 Loss: 0.010903593828418127 Validation Loss: 0.013588377598816715 \n",
      "Epoch: 190 Loss: 0.010761997861079533 Validation Loss: 0.016607693938271804 \n",
      "Epoch: 191 Loss: 0.01087133356591302 Validation Loss: 0.013572487531577386 \n",
      "Epoch: 192 Loss: 0.010731020521601473 Validation Loss: 0.01658782193014193 \n",
      "Epoch: 193 Loss: 0.010839485724025795 Validation Loss: 0.013556988583402152 \n",
      "Epoch: 194 Loss: 0.010700419448548945 Validation Loss: 0.016568268949029893 \n",
      "Epoch: 195 Loss: 0.010808034128264006 Validation Loss: 0.013541881971190052 \n",
      "Epoch: 196 Loss: 0.010670179484093868 Validation Loss: 0.01654904419025385 \n",
      "Epoch: 197 Loss: 0.010776960428267897 Validation Loss: 0.01352713388874979 \n",
      "Epoch: 198 Loss: 0.010640286825471326 Validation Loss: 0.016530154671768958 \n",
      "Epoch: 199 Loss: 0.010746247925281498 Validation Loss: 0.0135126762242907 \n",
      "Epoch: 200 Loss: 0.01061073042398601 Validation Loss: 0.01651160269325824 \n",
      "Epoch: 201 Loss: 0.01071588081040148 Validation Loss: 0.013498414369283588 \n",
      "Epoch: 202 Loss: 0.010581499528523932 Validation Loss: 0.016493377548854733 \n",
      "Epoch: 203 Loss: 0.010685840968464717 Validation Loss: 0.01348423996650804 \n",
      "Epoch: 204 Loss: 0.01055258143120649 Validation Loss: 0.016475449829806164 \n",
      "Epoch: 205 Loss: 0.010656107451106704 Validation Loss: 0.013470043804384862 \n",
      "Epoch: 206 Loss: 0.01052396332314768 Validation Loss: 0.01645777563578019 \n",
      "Epoch: 207 Loss: 0.010626660441059109 Validation Loss: 0.013455723281145287 \n",
      "Epoch: 208 Loss: 0.010495637573183341 Validation Loss: 0.016440308768934674 \n",
      "Epoch: 209 Loss: 0.010597486086085448 Validation Loss: 0.013441181619208197 \n",
      "Epoch: 210 Loss: 0.010467606084826726 Validation Loss: 0.01642301184225311 \n",
      "Epoch: 211 Loss: 0.010568577213913933 Validation Loss: 0.013426318861866097 \n",
      "Epoch: 212 Loss: 0.010439881011801324 Validation Loss: 0.016405860166664083 \n",
      "Epoch: 213 Loss: 0.010539929102211376 Validation Loss: 0.01341101528648452 \n",
      "Epoch: 214 Loss: 0.010412484234591568 Validation Loss: 0.016388841776815516 \n",
      "Epoch: 215 Loss: 0.010511534167334493 Validation Loss: 0.013395106561951649 \n",
      "Epoch: 216 Loss: 0.010385451364443753 Validation Loss: 0.016371963363425543 \n",
      "Epoch: 217 Loss: 0.010483379562337192 Validation Loss: 0.013378345455991071 \n",
      "Epoch: 218 Loss: 0.010358845951645388 Validation Loss: 0.016355271940275543 \n",
      "Epoch: 219 Loss: 0.010455448039236584 Validation Loss: 0.013360336180119793 \n",
      "Epoch: 220 Loss: 0.010332789309689349 Validation Loss: 0.016338901513503788 \n",
      "Epoch: 221 Loss: 0.010427720841184958 Validation Loss: 0.01334042897359592 \n",
      "Epoch: 222 Loss: 0.010307508722990215 Validation Loss: 0.016323150571072746 \n",
      "Epoch: 223 Loss: 0.010400192332823854 Validation Loss: 0.013317693982937652 \n",
      "Epoch: 224 Loss: 0.010283341760409095 Validation Loss: 0.01630849346166239 \n",
      "Epoch: 225 Loss: 0.010372955223615232 Validation Loss: 0.01329183745252845 \n",
      "Epoch: 226 Loss: 0.010260279472244052 Validation Loss: 0.016294835184531765 \n",
      "Epoch: 227 Loss: 0.010346414891058222 Validation Loss: 0.013266011397634118 \n",
      "Epoch: 228 Loss: 0.010236903156200855 Validation Loss: 0.016279761319961637 \n",
      "Epoch: 229 Loss: 0.010320699482668387 Validation Loss: 0.013244341479386322 \n",
      "Epoch: 230 Loss: 0.01021170522555048 Validation Loss: 0.01626099329803294 \n",
      "Epoch: 231 Loss: 0.010294432313239156 Validation Loss: 0.013224461086766824 \n",
      "Epoch: 232 Loss: 0.0101851469870447 Validation Loss: 0.016239667495858215 \n",
      "Epoch: 233 Loss: 0.010266979608689419 Validation Loss: 0.013202336585137078 \n",
      "Epoch: 234 Loss: 0.010158874688384471 Validation Loss: 0.016218590665584356 \n",
      "Epoch: 235 Loss: 0.010239728769035 Validation Loss: 0.013177769890117192 \n",
      "Epoch: 236 Loss: 0.010134227169820854 Validation Loss: 0.01619991251325329 \n",
      "Epoch: 237 Loss: 0.010214054371086613 Validation Loss: 0.013152925987822946 \n",
      "Epoch: 238 Loss: 0.01011108673451597 Validation Loss: 0.01618340978494621 \n",
      "Epoch: 239 Loss: 0.010189631851812158 Validation Loss: 0.013128976839701621 \n",
      "Epoch: 240 Loss: 0.010088259764122589 Validation Loss: 0.01616714090283955 \n",
      "Epoch: 241 Loss: 0.010165089162369108 Validation Loss: 0.01310526137963546 \n",
      "Epoch: 242 Loss: 0.010064802045232135 Validation Loss: 0.01614958147001059 \n",
      "Epoch: 243 Loss: 0.010139663971709949 Validation Loss: 0.013080830937271136 \n",
      "Epoch: 244 Loss: 0.010040784871339272 Validation Loss: 0.01613086846763151 \n",
      "Epoch: 245 Loss: 0.010113817656639545 Validation Loss: 0.013055699490572047 \n",
      "Epoch: 246 Loss: 0.010016941241582342 Validation Loss: 0.01611224764918081 \n",
      "Epoch: 247 Loss: 0.010088459951114128 Validation Loss: 0.013030543497624798 \n",
      "Epoch: 248 Loss: 0.009993833239937435 Validation Loss: 0.016094717353868873 \n",
      "Epoch: 249 Loss: 0.010063954512072489 Validation Loss: 0.013005734702482332 \n",
      "Epoch: 250 Loss: 0.009971433182431372 Validation Loss: 0.01607830379067762 \n",
      "Epoch: 251 Loss: 0.010039936324226235 Validation Loss: 0.012980988612118808 \n",
      "Epoch: 252 Loss: 0.00994934875470159 Validation Loss: 0.016062381736023344 \n",
      "Epoch: 253 Loss: 0.010015873252768903 Validation Loss: 0.012955871117119282 \n",
      "Epoch: 254 Loss: 0.009927264613181087 Validation Loss: 0.016046382581511746 \n",
      "Epoch: 255 Loss: 0.00999163124101322 Validation Loss: 0.01293051418152148 \n",
      "Epoch: 256 Loss: 0.009905106208674646 Validation Loss: 0.016030080381096014 \n",
      "Epoch: 257 Loss: 0.009967526594814714 Validation Loss: 0.012905782492438093 \n",
      "Epoch: 258 Loss: 0.00988289174715012 Validation Loss: 0.01601340884971627 \n",
      "Epoch: 259 Loss: 0.00994393119050179 Validation Loss: 0.012882540888441634 \n",
      "Epoch: 260 Loss: 0.009860629594745002 Validation Loss: 0.01599640525210091 \n",
      "Epoch: 261 Loss: 0.009920831300928218 Validation Loss: 0.012860533810426861 \n",
      "Epoch: 262 Loss: 0.009838421796520896 Validation Loss: 0.015979448102084536 \n",
      "Epoch: 263 Loss: 0.009897759579497047 Validation Loss: 0.012838109002638388 \n",
      "Epoch: 264 Loss: 0.009816564434529069 Validation Loss: 0.015963306980444736 \n",
      "Epoch: 265 Loss: 0.009874252409113765 Validation Loss: 0.012813565297809016 \n",
      "Epoch: 266 Loss: 0.009795382247676693 Validation Loss: 0.015948576157271625 \n",
      "Epoch: 267 Loss: 0.009850456343866644 Validation Loss: 0.012787489202587744 \n",
      "Epoch: 268 Loss: 0.009774684371801302 Validation Loss: 0.015934523347411092 \n",
      "Epoch: 269 Loss: 0.009827282098865997 Validation Loss: 0.012763733387345832 \n",
      "Epoch: 270 Loss: 0.009753512656141433 Validation Loss: 0.01591886069976265 \n",
      "Epoch: 271 Loss: 0.009805877023668865 Validation Loss: 0.012746686970242175 \n",
      "Epoch: 272 Loss: 0.009731091339121098 Validation Loss: 0.01590006800756153 \n",
      "Epoch: 273 Loss: 0.009786236866526594 Validation Loss: 0.012736102381295104 \n",
      "Epoch: 274 Loss: 0.009707693323215671 Validation Loss: 0.015879563544730628 \n",
      "Epoch: 275 Loss: 0.009765641000909391 Validation Loss: 0.012721712806464476 \n",
      "Epoch: 276 Loss: 0.009685571966180783 Validation Loss: 0.01586365101837148 \n",
      "Epoch: 277 Loss: 0.009739818681261786 Validation Loss: 0.012683705226264505 \n",
      "Epoch: 278 Loss: 0.009670912074545122 Validation Loss: 0.015865210887387245 \n",
      "Epoch: 279 Loss: 0.009706745601582757 Validation Loss: 0.01262317007881264 \n",
      "Epoch: 280 Loss: 0.009658233631308634 Validation Loss: 0.015866771041089803 \n",
      "Epoch: 281 Loss: 0.009681492472021722 Validation Loss: 0.012609443711611362 \n",
      "Epoch: 282 Loss: 0.009629121107337794 Validation Loss: 0.01583018183635111 \n",
      "Epoch: 283 Loss: 0.009682700429813503 Validation Loss: 0.01265918470854488 \n",
      "Epoch: 284 Loss: 0.009600919369896028 Validation Loss: 0.015792434881513242 \n",
      "Epoch: 285 Loss: 0.009681274919302974 Validation Loss: 0.012690767674078906 \n",
      "Epoch: 286 Loss: 0.009572518651109202 Validation Loss: 0.015768191797958873 \n",
      "Epoch: 287 Loss: 0.009637920092801835 Validation Loss: 0.012613292373379882 \n",
      "Epoch: 288 Loss: 0.00956679819347047 Validation Loss: 0.015792775208580186 \n",
      "Epoch: 289 Loss: 0.009593907635038552 Validation Loss: 0.012512084139894733 \n",
      "Epoch: 290 Loss: 0.009568251998723765 Validation Loss: 0.015819347515689183 \n",
      "Epoch: 291 Loss: 0.009569711693830718 Validation Loss: 0.012505864015173564 \n",
      "Epoch: 292 Loss: 0.009532015278474158 Validation Loss: 0.015770308624897585 \n",
      "Epoch: 293 Loss: 0.009576700648187702 Validation Loss: 0.012554584347251891 \n",
      "Epoch: 294 Loss: 0.009509135466967977 Validation Loss: 0.01574381412068934 \n",
      "Epoch: 295 Loss: 0.009578404182639777 Validation Loss: 0.012581185344449365 \n",
      "Epoch: 296 Loss: 0.009487100556652125 Validation Loss: 0.0157275928102111 \n",
      "Epoch: 297 Loss: 0.009544927548760811 Validation Loss: 0.01253404769867545 \n",
      "Epoch: 298 Loss: 0.00947168458863252 Validation Loss: 0.01572897697189246 \n",
      "Epoch: 299 Loss: 0.00950338731998593 Validation Loss: 0.012458714369083808 \n",
      "Epoch: 300 Loss: 0.009464702267882503 Validation Loss: 0.01574210435642421 \n",
      "Epoch: 301 Loss: 0.00947283295599139 Validation Loss: 0.012424435852073916 \n",
      "Epoch: 302 Loss: 0.009440139349513842 Validation Loss: 0.01571737296302285 \n",
      "Epoch: 303 Loss: 0.009466749488084202 Validation Loss: 0.012445658137983559 \n",
      "Epoch: 304 Loss: 0.009416402974291506 Validation Loss: 0.015689515282872803 \n",
      "Epoch: 305 Loss: 0.009473777208630818 Validation Loss: 0.012484233555454114 \n",
      "Epoch: 306 Loss: 0.00939605632976499 Validation Loss: 0.01567104057641875 \n",
      "Epoch: 307 Loss: 0.009456780450992887 Validation Loss: 0.012470014985471106 \n",
      "Epoch: 308 Loss: 0.009378626540091008 Validation Loss: 0.01566632135752334 \n",
      "Epoch: 309 Loss: 0.009417692674878042 Validation Loss: 0.012398901908080767 \n",
      "Epoch: 310 Loss: 0.009374926154142602 Validation Loss: 0.015687954134709567 \n",
      "Epoch: 311 Loss: 0.009378585509594362 Validation Loss: 0.012337749471236038 \n",
      "Epoch: 312 Loss: 0.009356685705346212 Validation Loss: 0.01567744355130607 \n",
      "Epoch: 313 Loss: 0.00936058146759431 Validation Loss: 0.012343378266170756 \n",
      "Epoch: 314 Loss: 0.009325879374341836 Validation Loss: 0.01563725161900146 \n",
      "Epoch: 315 Loss: 0.009373527695471553 Validation Loss: 0.01239897047210468 \n",
      "Epoch: 316 Loss: 0.009305627995430272 Validation Loss: 0.015613816546674904 \n",
      "Epoch: 317 Loss: 0.009374127177766898 Validation Loss: 0.01241680333165139 \n",
      "Epoch: 318 Loss: 0.009287690142928556 Validation Loss: 0.015605618912103872 \n",
      "Epoch: 319 Loss: 0.009336051227391211 Validation Loss: 0.012348695111680975 \n",
      "Epoch: 320 Loss: 0.009285948929878723 Validation Loss: 0.015632475650909715 \n",
      "Epoch: 321 Loss: 0.009293266486206653 Validation Loss: 0.012267122356596192 \n",
      "Epoch: 322 Loss: 0.009279155559833946 Validation Loss: 0.015644623356601953 \n",
      "Epoch: 323 Loss: 0.009264887420605224 Validation Loss: 0.012254111716811693 \n",
      "Epoch: 324 Loss: 0.009242188086577502 Validation Loss: 0.015596187107421226 \n",
      "Epoch: 325 Loss: 0.009272645925096062 Validation Loss: 0.012303861252163477 \n",
      "Epoch: 326 Loss: 0.009220406583466885 Validation Loss: 0.015568108440625115 \n",
      "Epoch: 327 Loss: 0.009286730701835184 Validation Loss: 0.012345216644682253 \n",
      "Epoch: 328 Loss: 0.009204225713127338 Validation Loss: 0.015558314936761923 \n",
      "Epoch: 329 Loss: 0.009258080627031673 Validation Loss: 0.012298307430660764 \n",
      "Epoch: 330 Loss: 0.00919834592159751 Validation Loss: 0.015576324652002812 \n",
      "Epoch: 331 Loss: 0.009216180280407969 Validation Loss: 0.012215196153600779 \n",
      "Epoch: 332 Loss: 0.009198489735264397 Validation Loss: 0.01560270303910574 \n",
      "Epoch: 333 Loss: 0.009180826935636259 Validation Loss: 0.012178116282524935 \n",
      "Epoch: 334 Loss: 0.009166036660401453 Validation Loss: 0.015565299515620353 \n",
      "Epoch: 335 Loss: 0.009176572787086664 Validation Loss: 0.012208983184078363 \n",
      "Epoch: 336 Loss: 0.009139169051313853 Validation Loss: 0.015528826518225748 \n",
      "Epoch: 337 Loss: 0.009196095343661842 Validation Loss: 0.012264452693879687 \n",
      "Epoch: 338 Loss: 0.009122908630543077 Validation Loss: 0.01551336467202393 \n",
      "Epoch: 339 Loss: 0.00918199490328519 Validation Loss: 0.012245378219566925 \n",
      "Epoch: 340 Loss: 0.009113971500673376 Validation Loss: 0.015523067198025365 \n",
      "Epoch: 341 Loss: 0.009142256969471248 Validation Loss: 0.012164823699959887 \n",
      "Epoch: 342 Loss: 0.009118633552056605 Validation Loss: 0.0155591864714061 \n",
      "Epoch: 343 Loss: 0.009102747263651172 Validation Loss: 0.012105537017703437 \n",
      "Epoch: 344 Loss: 0.009095340039515343 Validation Loss: 0.015540596728198536 \n",
      "Epoch: 345 Loss: 0.009087082943568341 Validation Loss: 0.01211789996570195 \n",
      "Epoch: 346 Loss: 0.009061975019443669 Validation Loss: 0.015494507256207164 \n",
      "Epoch: 347 Loss: 0.009106877679416458 Validation Loss: 0.012180428753191135 \n",
      "Epoch: 348 Loss: 0.009044020125720215 Validation Loss: 0.015471097997612562 \n",
      "Epoch: 349 Loss: 0.009107736907869361 Validation Loss: 0.01218888508109467 \n",
      "Epoch: 350 Loss: 0.009032925177863358 Validation Loss: 0.015472847935183246 \n",
      "Epoch: 351 Loss: 0.009070226858678036 Validation Loss: 0.012113018928514106 \n",
      "Epoch: 352 Loss: 0.00903911345234898 Validation Loss: 0.015512606226724731 \n",
      "Epoch: 353 Loss: 0.009029599016402452 Validation Loss: 0.01203746011329 \n",
      "Epoch: 354 Loss: 0.009027216907409416 Validation Loss: 0.015516274484737438 \n",
      "Epoch: 355 Loss: 0.009005340761855435 Validation Loss: 0.012032104715057177 \n",
      "Epoch: 356 Loss: 0.008989438023929448 Validation Loss: 0.015465189864659612 \n",
      "Epoch: 357 Loss: 0.00901968953915198 Validation Loss: 0.012090511690947495 \n",
      "Epoch: 358 Loss: 0.00896861373813479 Validation Loss: 0.015433956588039362 \n",
      "Epoch: 359 Loss: 0.009032473658861732 Validation Loss: 0.012121529756406912 \n",
      "Epoch: 360 Loss: 0.008956191194330254 Validation Loss: 0.015428308483280358 \n",
      "Epoch: 361 Loss: 0.008999683828487202 Validation Loss: 0.012056077644915534 \n",
      "Epoch: 362 Loss: 0.008960669376219855 Validation Loss: 0.015464363646797308 \n",
      "Epoch: 363 Loss: 0.008959723315654387 Validation Loss: 0.011972173814879673 \n",
      "Epoch: 364 Loss: 0.00895836667986433 Validation Loss: 0.015486700322368459 \n",
      "Epoch: 365 Loss: 0.008930422427664548 Validation Loss: 0.011950574829525508 \n",
      "Epoch: 366 Loss: 0.00892103618878543 Validation Loss: 0.015439020842181182 \n",
      "Epoch: 367 Loss: 0.008937531179393323 Validation Loss: 0.011999661056973955 \n",
      "Epoch: 368 Loss: 0.008896467455834407 Validation Loss: 0.015400186018770285 \n",
      "Epoch: 369 Loss: 0.008956905489076765 Validation Loss: 0.012045325783827093 \n",
      "Epoch: 370 Loss: 0.008882593749463139 Validation Loss: 0.015387022186525422 \n",
      "Epoch: 371 Loss: 0.008930023594375797 Validation Loss: 0.011991440081195497 \n",
      "Epoch: 372 Loss: 0.008885138209618084 Validation Loss: 0.01541805417866424 \n",
      "Epoch: 373 Loss: 0.0088909764358885 Validation Loss: 0.011902715821099103 \n",
      "Epoch: 374 Loss: 0.008889571216233082 Validation Loss: 0.015453851470912449 \n",
      "Epoch: 375 Loss: 0.008859288089872255 Validation Loss: 0.011868444666668964 \n",
      "Epoch: 376 Loss: 0.008855069303540549 Validation Loss: 0.01541324234232342 \n",
      "Epoch: 377 Loss: 0.008861221970206539 Validation Loss: 0.011910087451890346 \n",
      "Epoch: 378 Loss: 0.008827195543208712 Validation Loss: 0.01536807639331064 \n",
      "Epoch: 379 Loss: 0.008883793402486016 Validation Loss: 0.011964567468484493 \n",
      "Epoch: 380 Loss: 0.008811648231806279 Validation Loss: 0.015347647127864374 \n",
      "Epoch: 381 Loss: 0.008861163187161587 Validation Loss: 0.011918651961051364 \n",
      "Epoch: 382 Loss: 0.008812957707519855 Validation Loss: 0.015374875000035029 \n",
      "Epoch: 383 Loss: 0.00882264481975041 Validation Loss: 0.011826424377619315 \n",
      "Epoch: 384 Loss: 0.008821835195790556 Validation Loss: 0.015420103537471617 \n",
      "Epoch: 385 Loss: 0.008790520920912377 Validation Loss: 0.011784880312199774 \n",
      "Epoch: 386 Loss: 0.008790304271763688 Validation Loss: 0.015386447334299336 \n",
      "Epoch: 387 Loss: 0.008790204918152154 Validation Loss: 0.01182354443947559 \n",
      "Epoch: 388 Loss: 0.008760362623189582 Validation Loss: 0.015337215382261805 \n",
      "Epoch: 389 Loss: 0.008813849362500889 Validation Loss: 0.011883037970899632 \n",
      "Epoch: 390 Loss: 0.008743336387918275 Validation Loss: 0.015311104587017007 \n",
      "Epoch: 391 Loss: 0.008792934080411725 Validation Loss: 0.011841382966682846 \n",
      "Epoch: 392 Loss: 0.008744142817372454 Validation Loss: 0.01533658538547528 \n",
      "Epoch: 393 Loss: 0.008754771873460177 Validation Loss: 0.011747843078251264 \n",
      "Epoch: 394 Loss: 0.008755432787558961 Validation Loss: 0.015387870343273201 \n",
      "Epoch: 395 Loss: 0.008723705444128397 Validation Loss: 0.01170469007176948 \n",
      "Epoch: 396 Loss: 0.008726141747062661 Validation Loss: 0.015359504683353889 \n",
      "Epoch: 397 Loss: 0.008723932822224851 Validation Loss: 0.011744615620931133 \n",
      "Epoch: 398 Loss: 0.008695617975916328 Validation Loss: 0.015308358627100338 \n",
      "Epoch: 399 Loss: 0.008747475717834985 Validation Loss: 0.011805913450085569 \n",
      "Epoch: 400 Loss: 0.008677445591181105 Validation Loss: 0.015278277215433417 \n",
      "Epoch: 401 Loss: 0.008725453648766547 Validation Loss: 0.011762748880107188 \n",
      "Epoch: 402 Loss: 0.008678751522976284 Validation Loss: 0.015304861181996357 \n",
      "Epoch: 403 Loss: 0.008687580779432434 Validation Loss: 0.011667765166512484 \n",
      "Epoch: 404 Loss: 0.008691166833534969 Validation Loss: 0.015360035582906405 \n",
      "Epoch: 405 Loss: 0.008658661567749417 Validation Loss: 0.011627443498577769 \n",
      "Epoch: 406 Loss: 0.008662681160164581 Validation Loss: 0.015333686295589233 \n",
      "Epoch: 407 Loss: 0.008661953326221763 Validation Loss: 0.011672845733415215 \n",
      "Epoch: 408 Loss: 0.008632610004511206 Validation Loss: 0.015281289923685918 \n",
      "Epoch: 409 Loss: 0.00868465559578381 Validation Loss: 0.01173336831224846 \n",
      "Epoch: 410 Loss: 0.008613671220977257 Validation Loss: 0.015248824740621727 \n",
      "Epoch: 411 Loss: 0.00865868008858253 Validation Loss: 0.011682310926216043 \n",
      "Epoch: 412 Loss: 0.008616885051634427 Validation Loss: 0.015280359954629555 \n",
      "Epoch: 413 Loss: 0.008621188592990214 Validation Loss: 0.011585993048274968 \n",
      "Epoch: 414 Loss: 0.008629248640803727 Validation Loss: 0.015337400747883364 \n",
      "Epoch: 415 Loss: 0.008595695412372397 Validation Loss: 0.011553745709317555 \n",
      "Epoch: 416 Loss: 0.008600101338579103 Validation Loss: 0.015309325663929636 \n",
      "Epoch: 417 Loss: 0.008604267198476193 Validation Loss: 0.01160892514366446 \n",
      "Epoch: 418 Loss: 0.008570995115622244 Validation Loss: 0.015255262414445851 \n",
      "Epoch: 419 Loss: 0.00862433236140167 Validation Loss: 0.011664415325291392 \n",
      "Epoch: 420 Loss: 0.008551937370015802 Validation Loss: 0.015222884729164093 \n",
      "Epoch: 421 Loss: 0.00859224813055645 Validation Loss: 0.011599800732112385 \n",
      "Epoch: 422 Loss: 0.008558781145213327 Validation Loss: 0.01526395678419776 \n",
      "Epoch: 423 Loss: 0.008555827541737157 Validation Loss: 0.011504652094981343 \n",
      "Epoch: 424 Loss: 0.008569023940248171 Validation Loss: 0.015319012815757474 \n",
      "Epoch: 425 Loss: 0.008535664319921813 Validation Loss: 0.011486748945211473 \n",
      "Epoch: 426 Loss: 0.008538595064085198 Validation Loss: 0.015286333310075504 \n",
      "Epoch: 427 Loss: 0.008551061437517245 Validation Loss: 0.011554789883188395 \n",
      "Epoch: 428 Loss: 0.008510420876918258 Validation Loss: 0.015229729578722893 \n",
      "Epoch: 429 Loss: 0.008564496584833705 Validation Loss: 0.011597209880129066 \n",
      "Epoch: 430 Loss: 0.008492560541177335 Validation Loss: 0.015201910204725435 \n",
      "Epoch: 431 Loss: 0.008525985527698777 Validation Loss: 0.011516126647049393 \n",
      "Epoch: 432 Loss: 0.008504509908510361 Validation Loss: 0.015256575607274524 \n",
      "Epoch: 433 Loss: 0.008491969876353282 Validation Loss: 0.011428075368653787 \n",
      "Epoch: 434 Loss: 0.008509447012841124 Validation Loss: 0.015303319895999078 \n",
      "Epoch: 435 Loss: 0.008479498782738433 Validation Loss: 0.011430934672694296 \n",
      "Epoch: 436 Loss: 0.00847830408599335 Validation Loss: 0.015264414698350338 \n",
      "Epoch: 437 Loss: 0.008501938918767455 Validation Loss: 0.011512040656829073 \n",
      "Epoch: 438 Loss: 0.008450467541450178 Validation Loss: 0.015204676037536929 \n",
      "Epoch: 439 Loss: 0.008502787925646245 Validation Loss: 0.011529627835922958 \n",
      "Epoch: 440 Loss: 0.008436319807880455 Validation Loss: 0.015188773456382256 \n",
      "Epoch: 441 Loss: 0.008460338827090718 Validation Loss: 0.011433852597959527 \n",
      "Epoch: 442 Loss: 0.00845359521292514 Validation Loss: 0.015258096183241875 \n",
      "Epoch: 443 Loss: 0.008430633534907583 Validation Loss: 0.011361614496228757 \n",
      "Epoch: 444 Loss: 0.008449902034942116 Validation Loss: 0.015288811970377628 \n",
      "Epoch: 445 Loss: 0.008428217586632734 Validation Loss: 0.011390249366263679 \n",
      "Epoch: 446 Loss: 0.008419252861174856 Validation Loss: 0.01524239997509118 \n",
      "Epoch: 447 Loss: 0.008455138011420362 Validation Loss: 0.011478009710421143 \n",
      "Epoch: 448 Loss: 0.00839125738591045 Validation Loss: 0.015181049399549566 \n",
      "Epoch: 449 Loss: 0.008437722135995269 Validation Loss: 0.011458291040057649 \n",
      "Epoch: 450 Loss: 0.00838444601160417 Validation Loss: 0.01518662053152974 \n",
      "Epoch: 451 Loss: 0.0083960111001279 Validation Loss: 0.011354954601344334 \n",
      "Epoch: 452 Loss: 0.008404438343902572 Validation Loss: 0.0152649977402866 \n",
      "Epoch: 453 Loss: 0.008373356940563228 Validation Loss: 0.01130880159717812 \n",
      "Epoch: 454 Loss: 0.008390499815916545 Validation Loss: 0.015273227239963404 \n",
      "Epoch: 455 Loss: 0.008382843624980128 Validation Loss: 0.011365982170154759 \n",
      "Epoch: 456 Loss: 0.008360776974584537 Validation Loss: 0.015217229555075382 \n",
      "Epoch: 457 Loss: 0.008406340523853749 Validation Loss: 0.011442994845048975 \n",
      "Epoch: 458 Loss: 0.008333915154463226 Validation Loss: 0.015161121452247342 \n",
      "Epoch: 459 Loss: 0.0083701001489565 Validation Loss: 0.011380459144391657 \n",
      "Epoch: 460 Loss: 0.00833805639429654 Validation Loss: 0.015197169106341625 \n",
      "Epoch: 461 Loss: 0.00833349735565008 Validation Loss: 0.01128215433215034 \n",
      "Epoch: 462 Loss: 0.008354130381473018 Validation Loss: 0.015270238200505326 \n",
      "Epoch: 463 Loss: 0.00832163245506123 Validation Loss: 0.011272638891941477 \n",
      "Epoch: 464 Loss: 0.00833168486704377 Validation Loss: 0.015253596399680184 \n",
      "Epoch: 465 Loss: 0.008343469135958678 Validation Loss: 0.011357102396860958 \n",
      "Epoch: 466 Loss: 0.008301679630739913 Validation Loss: 0.015186654919379374 \n",
      "Epoch: 467 Loss: 0.008349387885364268 Validation Loss: 0.011395012401162922 \n",
      "Epoch: 468 Loss: 0.008280965361965192 Validation Loss: 0.015150979568414128 \n",
      "Epoch: 469 Loss: 0.008303141316256582 Validation Loss: 0.011299138956988293 \n",
      "Epoch: 470 Loss: 0.008296997765135157 Validation Loss: 0.015219161531068667 \n",
      "Epoch: 471 Loss: 0.00827473441456796 Validation Loss: 0.011224010586842942 \n",
      "Epoch: 472 Loss: 0.008300548759614074 Validation Loss: 0.015267296065067004 \n",
      "Epoch: 473 Loss: 0.00827716552930443 Validation Loss: 0.011257564068430622 \n",
      "Epoch: 474 Loss: 0.008273898874919711 Validation Loss: 0.015227393377358444 \n",
      "Epoch: 475 Loss: 0.00830560194570676 Validation Loss: 0.01135324886282892 \n",
      "Epoch: 476 Loss: 0.008242901333527099 Validation Loss: 0.01515535763505025 \n",
      "Epoch: 477 Loss: 0.008282460541014941 Validation Loss: 0.01132839457779247 \n",
      "Epoch: 478 Loss: 0.008235603236918654 Validation Loss: 0.015159113419237742 \n",
      "Epoch: 479 Loss: 0.008239973547543824 Validation Loss: 0.011223504953023693 \n",
      "Epoch: 480 Loss: 0.00825681350193428 Validation Loss: 0.0152429643698065 \n",
      "Epoch: 481 Loss: 0.008223881516759634 Validation Loss: 0.011190938723299985 \n",
      "Epoch: 482 Loss: 0.008245041005781873 Validation Loss: 0.015254245806211006 \n",
      "Epoch: 483 Loss: 0.008241704114876298 Validation Loss: 0.01126541009029336 \n",
      "Epoch: 484 Loss: 0.008216361855364727 Validation Loss: 0.015193081301899633 \n",
      "Epoch: 485 Loss: 0.008259049736260125 Validation Loss: 0.011333578979627655 \n",
      "Epoch: 486 Loss: 0.008189050885421168 Validation Loss: 0.015135291210668441 \n",
      "Epoch: 487 Loss: 0.008214016613506087 Validation Loss: 0.011251673398796631 \n",
      "Epoch: 488 Loss: 0.008199021125666749 Validation Loss: 0.015187474617586575 \n",
      "Epoch: 489 Loss: 0.008182693716540415 Validation Loss: 0.011165489569625618 \n",
      "Epoch: 490 Loss: 0.008211595123594843 Validation Loss: 0.015255678381197232 \n",
      "Epoch: 491 Loss: 0.008182872219766636 Validation Loss: 0.01118614684282492 \n",
      "Epoch: 492 Loss: 0.00818952009647816 Validation Loss: 0.015230359173807773 \n",
      "Epoch: 493 Loss: 0.00821132627007438 Validation Loss: 0.01128550171499339 \n",
      "Epoch: 494 Loss: 0.008157486823970696 Validation Loss: 0.015153512686187288 \n",
      "Epoch: 495 Loss: 0.00819610690260056 Validation Loss: 0.011282622752157275 \n",
      "Epoch: 496 Loss: 0.008144146132551995 Validation Loss: 0.01513930940673868 \n",
      "Epoch: 497 Loss: 0.008150998428619827 Validation Loss: 0.011177881372275851 \n",
      "Epoch: 498 Loss: 0.00816552210125582 Validation Loss: 0.015223759955098755 \n",
      "Epoch: 499 Loss: 0.008134227914408978 Validation Loss: 0.011136692589356864 \n",
      "Epoch: 500 Loss: 0.008160515049469977 Validation Loss: 0.015251131726403126 \n"
     ]
    }
   ],
   "source": [
    "import nnet\n",
    "\n",
    "model = nnet.Sequential([\n",
    "    nnet.layers.Dense((13, 10), nnet.activation.Tanh),\n",
    "    nnet.layers.Dense((10, 8), nnet.activation.Tanh),\n",
    "    nnet.layers.Dense((8, 2), nnet.activation.Sigmoid)\n",
    "])\n",
    "\n",
    "model.fit(X_train, Y_train, 500, nnet.loss.MeanSquaredError, nnet.optimizers.RMSProp(), X_val=X_test, Y_val=Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0852953792565267"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test model accuracy using Mean Absolute Error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "mean_absolute_error(Y_test, y_pred.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actual testing\n",
    "def test_prediction(index):\n",
    "    y_pred = model.predict(np.array([X_test[index]]))\n",
    "    y_true = np.array([Y_test[index]])\n",
    "    \n",
    "    print('Prediction', y_scaler.inverse_transform(y_pred.T))\n",
    "    print('Actual', y_scaler.inverse_transform(y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction [[ 1.04694014 22.86797534]]\n",
      "Actual [[ 1.0433 24.5   ]]\n"
     ]
    }
   ],
   "source": [
    "test_prediction(18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction [[ 1.06170283 15.85686135]]\n",
      "Actual [[ 1.0646 15.    ]]\n"
     ]
    }
   ],
   "source": [
    "test_prediction(19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction [[ 1.04959195 22.11674905]]\n",
      "Actual [[ 1.0418 25.2   ]]\n"
     ]
    }
   ],
   "source": [
    "test_prediction(27)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3e248e8823122d6c7234371ee991cc4810791faba3b9f400ab196a38c557164b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
